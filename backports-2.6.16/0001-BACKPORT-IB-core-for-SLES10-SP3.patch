From: Vladimir Sokolovsky <vlad@mellanox.com>
Subject: [PATCH] BACKPORT: IB/core for SLES10 SP3

Change-Id: I232f87c4f9698a45affea2be5b6821bb16c2c1ef
Signed-off-by: Vladimir Sokolovsky <vlad@mellanox.com>
---
 drivers/infiniband/core/addr.c        |   70 +++++++++
 drivers/infiniband/core/cm.c          |   44 ++++++
 drivers/infiniband/core/cma.c         |   39 +++++
 drivers/infiniband/core/device.c      |   14 ++
 drivers/infiniband/core/mad.c         |  122 +++++++++++++++
 drivers/infiniband/core/netlink.c     |    2 +
 drivers/infiniband/core/peer_mem.c    |    5 +-
 drivers/infiniband/core/sysfs.c       |  129 ++++++++++++++++
 drivers/infiniband/core/ucm.c         |  122 +++++++++++++++
 drivers/infiniband/core/ucma.c        |   48 ++++++
 drivers/infiniband/core/umem.c        |   18 +++
 drivers/infiniband/core/user_mad.c    |  266 +++++++++++++++++++++++++++++++++
 drivers/infiniband/core/uverbs.h      |    7 +
 drivers/infiniband/core/uverbs_cmd.c  |    6 +
 drivers/infiniband/core/uverbs_main.c |  265 ++++++++++++++++++++++++++++++++
 drivers/infiniband/core/verbs.c       |    4 +
 include/rdma/ib_addr.h                |   24 +++
 include/rdma/ib_cm.h                  |   14 ++
 include/rdma/ib_pma.h                 |   12 ++
 include/rdma/ib_smi.h                 |   20 +++
 include/rdma/ib_umem.h                |    2 +
 include/rdma/ib_user_verbs.h          |    4 +
 include/rdma/ib_verbs.h               |    7 +
 include/rdma/peer_mem.h               |    3 +
 24 files changed, 1244 insertions(+), 3 deletions(-)

diff --git a/drivers/infiniband/core/addr.c b/drivers/infiniband/core/addr.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/addr.c
+++ b/drivers/infiniband/core/addr.c
@@ -111,7 +111,11 @@ int rdma_translate_ip(struct sockaddr *addr, struct rdma_dev_addr *dev_addr,
 	int ret = -EADDRNOTAVAIL;
 
 	if (dev_addr->bound_dev_if) {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		dev = dev_get_by_index(&init_net, dev_addr->bound_dev_if);
+#else
+		dev = dev_get_by_index(dev_addr->bound_dev_if);
+#endif
 		if (!dev)
 			return -ENODEV;
 		ret = rdma_copy_addr(dev_addr, dev, NULL);
@@ -135,6 +139,7 @@ int rdma_translate_ip(struct sockaddr *addr, struct rdma_dev_addr *dev_addr,
 
 #if IS_ENABLED(CONFIG_IPV6)
 	case AF_INET6:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		rcu_read_lock();
 		for_each_netdev_rcu(&init_net, dev) {
 			if (ipv6_chk_addr(&init_net,
@@ -147,6 +152,17 @@ int rdma_translate_ip(struct sockaddr *addr, struct rdma_dev_addr *dev_addr,
 			}
 		}
 		rcu_read_unlock();
+#else
+		read_lock(&dev_base_lock);
+		for (dev = dev_base; dev; dev = dev->next) {
+			if (ipv6_chk_addr(&((struct sockaddr_in6 *) addr)->sin6_addr,
+					  dev, 1)) {
+				ret = rdma_copy_addr(dev_addr, dev, NULL);
+				break;
+			}
+		}
+		read_unlock(&dev_base_lock);
+#endif
 		break;
 #endif
 	}
@@ -158,11 +174,18 @@ static void set_timeout(unsigned long time)
 {
 	unsigned long delay;
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+	cancel_delayed_work(&work);
+#endif
 	delay = time - jiffies;
 	if ((long)delay <= 0)
 		delay = 1;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	mod_delayed_work(addr_wq, &work, delay);
+#else
+	queue_delayed_work(addr_wq, &work, delay);
+#endif
 }
 
 static void queue_req(struct addr_req *req)
@@ -366,13 +389,21 @@ static int addr6_resolve(struct sockaddr_in6 *src_in,
 	ipv6_addr_copy(&fl.fl6_src, &src_in->sin6_addr);
 	fl.oif = addr->bound_dev_if;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	dst = ip6_route_output(&init_net, NULL, &fl);
+#else
+	dst = ip6_route_output(NULL, &fl);
+#endif
 	if ((ret = dst->error))
 		goto put;
 
 	if (ipv6_addr_any(&fl.fl6_src)) {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 		ret = ipv6_dev_get_saddr(&init_net, ip6_dst_idev(dst)->dev,
 					 &fl.fl6_dst, 0, &fl.fl6_src);
+#else
+		ret = ipv6_get_saddr(dst, &fl.fl6_dst, &fl.fl6_src);
+#endif
 		if (ret)
 			goto put;
 
@@ -549,6 +580,7 @@ void rdma_addr_cancel(struct rdma_dev_addr *addr)
 }
 EXPORT_SYMBOL(rdma_addr_cancel);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 struct resolve_cb_context {
 	struct rdma_dev_addr *addr;
 	struct completion comp;
@@ -664,6 +696,44 @@ static void __exit addr_cleanup(void)
 	unregister_netevent_notifier(&nb);
 	destroy_workqueue(addr_wq);
 }
+#else /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
+static int addr_arp_recv(struct sk_buff *skb, struct net_device *dev,
+			 struct packet_type *pkt, struct net_device *orig_dev)
+{
+	struct arphdr *arp_hdr;
+
+	arp_hdr = (struct arphdr *) skb->nh.raw;
+
+	if (arp_hdr->ar_op == htons(ARPOP_REQUEST) ||
+	    arp_hdr->ar_op == htons(ARPOP_REPLY))
+		set_timeout(jiffies);
+
+	kfree_skb(skb);
+	return 0;
+}
+
+static struct packet_type addr_arp = {
+	.type           = __constant_htons(ETH_P_ARP),
+	.func           = addr_arp_recv,
+	.af_packet_priv = (void*) 1,
+};
+
+static int addr_init(void)
+{
+	addr_wq = create_singlethread_workqueue("ib_addr");
+	if (!addr_wq)
+		return -ENOMEM;
+
+	dev_add_pack(&addr_arp);
+	return 0;
+}
+
+static void addr_cleanup(void)
+{
+	dev_remove_pack(&addr_arp);
+	destroy_workqueue(addr_wq);
+}
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 module_init(addr_init);
 module_exit(addr_cleanup);
diff --git a/drivers/infiniband/core/cm.c b/drivers/infiniband/core/cm.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@ -47,6 +47,9 @@
 #include <linux/sysfs.h>
 #include <linux/workqueue.h>
 #include <linux/kdev_t.h>
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,16))
+#include <linux/etherdevice.h>
+#endif
 
 #include <rdma/ib_cache.h>
 #include <rdma/ib_cm.h>
@@ -171,7 +174,11 @@ struct cm_port {
 struct cm_device {
 	struct list_head list;
 	struct ib_device *ib_device;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct device *device;
+#else
+	struct class_device *device;
+#endif
 	u8 ack_delay;
 	struct cm_port *port[0];
 };
@@ -417,11 +424,15 @@ static int cm_alloc_id(struct cm_id_private *cm_id_priv)
 		ret = idr_get_new_above(&cm.local_id_table, cm_id_priv,
 					next_id, &id);
 		if (!ret)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 #if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			next_id = ((unsigned) id + 1) & MAX_IDR_MASK;
 #else
 			next_id = max(id + 1, 0);
 #endif
+#else /* LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16) */
+			next_id = ((unsigned) id + 1) & MAX_ID_MASK;
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16) */
 		spin_unlock_irqrestore(&cm.lock, flags);
 	} while( (ret == -EAGAIN) && idr_pre_get(&cm.local_id_table, GFP_KERNEL) );
 
@@ -3724,7 +3735,11 @@ static ssize_t cm_show_counter(struct kobject *obj, struct attribute *attr,
 		       atomic_long_read(&group->counter[cm_attr->index]));
 }
 
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 static const struct sysfs_ops cm_counter_ops = {
+#else
+static struct sysfs_ops cm_counter_ops = {
+#endif
 	.show = cm_show_counter
 };
 
@@ -3745,6 +3760,7 @@ static struct kobj_type cm_port_obj_type = {
 	.release = cm_release_port_obj
 };
 
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
 static char *cm_devnode(struct device *dev, umode_t *mode)
 #else
@@ -3755,11 +3771,16 @@ static char *cm_devnode(struct device *dev, mode_t *mode)
 		*mode = 0666;
 	return kasprintf(GFP_KERNEL, "infiniband/%s", dev_name(dev));
 }
+#endif
 
 struct class cm_class = {
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 	.owner   = THIS_MODULE,
 	.name    = "infiniband_cm",
 	.devnode = cm_devnode,
+#else
+	.name    = "infiniband_cm",
+#endif
 };
 EXPORT_SYMBOL(cm_class);
 
@@ -3788,8 +3809,13 @@ static int cm_create_port_fs(struct cm_port *port)
 
 error:
 	while (i--)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 		kobject_put(&port->counter_group[i].obj);
 	kobject_put(&port->port_obj);
+#else
+		kobject_unregister(&port->counter_group[i].obj);
+	kobject_unregister(&port->port_obj);
+#endif
 	return ret;
 
 }
@@ -3799,9 +3825,15 @@ static void cm_remove_port_fs(struct cm_port *port)
 	int i;
 
 	for (i = 0; i < CM_COUNTER_GROUPS; i++)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 		kobject_put(&port->counter_group[i].obj);
 
 	kobject_put(&port->port_obj);
+#else
+		kobject_unregister(&port->counter_group[i].obj);
+
+	kobject_unregister(&port->port_obj);
+#endif
 }
 
 static void cm_add_one(struct ib_device *ib_device)
@@ -3830,7 +3862,11 @@ static void cm_add_one(struct ib_device *ib_device)
 	cm_dev->ib_device = ib_device;
 	cm_get_ack_delay(cm_dev);
 
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 	cm_dev->device = device_create(&cm_class, &ib_device->dev,
+#else
+	cm_dev->device = class_device_create(&cm_class, &ib_device->class_dev,
+#endif
 				       MKDEV(0, 0), NULL,
 				       "%s", ib_device->name);
 	if (IS_ERR(cm_dev->device)) {
@@ -3886,7 +3922,11 @@ error1:
 		ib_unregister_mad_agent(port->mad_agent);
 		cm_remove_port_fs(port);
 	}
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 	device_unregister(cm_dev->device);
+#else
+	class_device_unregister(cm_dev->device);
+#endif
 	kfree(cm_dev);
 }
 
@@ -3915,7 +3955,11 @@ static void cm_remove_one(struct ib_device *ib_device)
 		flush_workqueue(cm.wq);
 		cm_remove_port_fs(port);
 	}
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)
 	device_unregister(cm_dev->device);
+#else
+	class_device_unregister(cm_dev->device);
+#endif
 	kfree(cm_dev);
 }
 
diff --git a/drivers/infiniband/core/cma.c b/drivers/infiniband/core/cma.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -578,7 +578,9 @@ static int cma_modify_qp_rtr(struct rdma_id_private *id_priv,
 {
 	struct ib_qp_attr qp_attr;
 	int qp_attr_mask, ret;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	union ib_gid sgid;
+#endif
 
 	mutex_lock(&id_priv->qp_mutex);
 	if (!id_priv->id.qp) {
@@ -600,6 +602,7 @@ static int cma_modify_qp_rtr(struct rdma_id_private *id_priv,
 	ret = rdma_init_qp_attr(&id_priv->id, &qp_attr, &qp_attr_mask);
 	if (ret)
 		goto out;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	ret = ib_query_gid(id_priv->id.device, id_priv->id.port_num,
 			   qp_attr.ah_attr.grh.sgid_index, &sgid);
 	if (ret)
@@ -614,6 +617,7 @@ static int cma_modify_qp_rtr(struct rdma_id_private *id_priv,
 		if (ret)
 			goto out;
 	}
+#endif
 
 	if (conn_param)
 		qp_attr.max_dest_rd_atomic = conn_param->responder_resources;
@@ -1342,6 +1346,7 @@ static int cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event)
 	if (ret)
 		goto err3;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	if (is_iboe && !is_sidr) {
 		if (ib_event->param.req_rcvd.primary_path != NULL)
 			rdma_addr_find_smac_by_sgid(
@@ -1356,6 +1361,7 @@ static int cma_req_handler(struct ib_cm_id *cm_id, struct ib_cm_event *ib_event)
 		else
 			palt_smac = NULL;
 	}
+#endif
 	/*
 	 * Acquire mutex to prevent user executing rdma_destroy_id()
 	 * while we're accessing the cm_id.
@@ -1951,7 +1957,11 @@ static int cma_resolve_iboe_route(struct rdma_id_private *id_priv)
 	route->num_paths = 1;
 
 	if (addr->dev_addr.bound_dev_if)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 		ndev = dev_get_by_index(&init_net, addr->dev_addr.bound_dev_if);
+#else
+		ndev = dev_get_by_index(addr->dev_addr.bound_dev_if);
+#endif
 	if (!ndev) {
 		ret = -ENODEV;
 		goto err2;
@@ -2575,6 +2585,7 @@ int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)
 			goto err1;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (!(id_priv->options & (1 << CMA_OPTION_AFONLY))) {
 		if (addr->sa_family == AF_INET)
 			id_priv->afonly = 1;
@@ -2583,6 +2594,7 @@ int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)
 			id_priv->afonly = init_net.ipv6.sysctl.bindv6only;
 #endif
 	}
+#endif
 	ret = cma_get_port(id_priv);
 	if (ret)
 		goto err2;
@@ -3169,7 +3181,11 @@ static int cma_ib_mc_handler(int status, struct ib_sa_multicast *multicast)
 	memset(&event, 0, sizeof event);
 	event.status = status;
 	event.param.ud.private_data = mc->context;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	ndev = dev_get_by_index(&init_net, dev_addr->bound_dev_if);
+#else
+	ndev = dev_get_by_index(dev_addr->bound_dev_if);
+#endif
 	if (!ndev) {
 		status = -ENODEV;
 	} else {
@@ -3223,7 +3239,11 @@ static void cma_set_mgid(struct rdma_id_private *id_priv,
 		/* IPv6 address is an SA assigned MGID. */
 		memcpy(mgid, &sin6->sin6_addr, sizeof *mgid);
 	} else if ((addr->sa_family == AF_INET6)) {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		ipv6_ib_mc_map(&sin6->sin6_addr, dev_addr->broadcast, mc_map);
+#else
+		ipv6_ib_mc_map(&sin6->sin6_addr, mc_map);
+#endif
 		if (id_priv->id.ps == RDMA_PS_UDP)
 			mc_map[7] = 0x01;	/* Use RDMA CM signature */
 		*mgid = *(union ib_gid *) (mc_map + 4);
@@ -3286,7 +3306,14 @@ static int cma_join_ib_multicast(struct rdma_id_private *id_priv,
 						id_priv->id.port_num, &rec,
 						comp_mask, GFP_KERNEL,
 						cma_ib_mc_handler, mc);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	return PTR_RET(mc->multicast.ib);
+#else
+	if (IS_ERR(mc->multicast.ib))
+		return PTR_ERR(mc->multicast.ib);
+
+	return 0;
+#endif
 }
 
 static void iboe_mcast_work_handler(struct work_struct *work)
@@ -3356,7 +3383,11 @@ static int cma_iboe_join_multicast(struct rdma_id_private *id_priv,
 		mc->multicast.ib->rec.qkey = cpu_to_be32(RDMA_UDP_QKEY);
 
 	if (dev_addr->bound_dev_if)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		ndev = dev_get_by_index(&init_net, dev_addr->bound_dev_if);
+#else
+		ndev = dev_get_by_index(dev_addr->bound_dev_if);
+#endif
 	if (!ndev) {
 		err = -ENODEV;
 		goto out2;
@@ -3508,8 +3539,10 @@ static int cma_netdev_callback(struct notifier_block *self, unsigned long event,
 	struct rdma_id_private *id_priv;
 	int ret = NOTIFY_DONE;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (dev_net(ndev) != &init_net)
 		return NOTIFY_DONE;
+#endif
 
 	if (event != NETDEV_BONDING_FAILOVER)
 		return NOTIFY_DONE;
@@ -3627,6 +3660,7 @@ static void cma_remove_one(struct ib_device *device)
 	kfree(cma_dev);
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static int cma_get_id_stats(struct sk_buff *skb, struct netlink_callback *cb)
 {
 	struct nlmsghdr *nlh;
@@ -3721,6 +3755,7 @@ static const struct ibnl_client_cbs cma_cb_table[] = {
 	[RDMA_NL_RDMA_CM_ID_STATS] = { .dump = cma_get_id_stats,
 				       .module = THIS_MODULE },
 };
+#endif
 
 static int __init cma_init(void)
 {
@@ -3742,8 +3777,10 @@ static int __init cma_init(void)
 	if (ret)
 		goto err;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (ibnl_add_client(RDMA_NL_RDMA_CM, RDMA_NL_RDMA_CM_NUM_OPS, cma_cb_table))
 		printk(KERN_WARNING "RDMA CMA: failed to add netlink callback\n");
+#endif
 
 	return 0;
 
@@ -3760,7 +3797,9 @@ err1:
 
 static void __exit cma_cleanup(void)
 {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	ibnl_remove_client(RDMA_NL_RDMA_CM);
+#endif
 	ib_unregister_client(&cma_client);
 	unregister_netdevice_notifier(&cma_nb);
 	rdma_addr_unregister_client(&addr_client);
diff --git a/drivers/infiniband/core/device.c b/drivers/infiniband/core/device.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@ -38,7 +38,11 @@
 #include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/mutex.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #include <rdma/rdma_netlink.h>
+#else
+#include <linux/workqueue.h>
+#endif
 
 #include "core_priv.h"
 
@@ -752,11 +756,13 @@ static int __init ib_core_init(void)
 		goto err;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	ret = ibnl_init();
 	if (ret) {
 		printk(KERN_WARNING "Couldn't init IB netlink interface\n");
 		goto err_sysfs;
 	}
+#endif
 
 	ret = ib_cache_setup();
 	if (ret) {
@@ -767,7 +773,9 @@ static int __init ib_core_init(void)
 	return 0;
 
 err_nl:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	ibnl_cleanup();
+#endif
 
 err_sysfs:
 	ib_sysfs_cleanup();
@@ -780,10 +788,16 @@ err:
 static void __exit ib_core_cleanup(void)
 {
 	ib_cache_cleanup();
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	ibnl_cleanup();
+#endif
 	ib_sysfs_cleanup();
 	/* Make sure that any pending umem accounting work is done. */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	destroy_workqueue(ib_wq);
+#else
+	flush_scheduled_work();
+#endif
 }
 
 module_init(ib_core_init);
diff --git a/drivers/infiniband/core/mad.c b/drivers/infiniband/core/mad.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/mad.c
+++ b/drivers/infiniband/core/mad.c
@@ -61,6 +61,7 @@ static struct kmem_cache *ib_mad_cache;
 static struct list_head ib_mad_port_list;
 static u32 ib_mad_client_id = 0;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 
 /*
  * Timeout FIFO (tf) param
@@ -78,6 +79,7 @@ enum {
 	MIN_TIME_FOR_SA_MAD_SEND_MS = 20,
 	MAX_SA_MADS = 10000
 };
+#endif
 
 /* Port list lock */
 static DEFINE_SPINLOCK(ib_mad_port_list_lock);
@@ -99,6 +101,7 @@ static int add_nonoui_reg_req(struct ib_mad_reg_req *mad_reg_req,
 			      u8 mgmt_class);
 static int add_oui_reg_req(struct ib_mad_reg_req *mad_reg_req,
 			   struct ib_mad_agent_private *agent_priv);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static int send_sa_cc_mad(struct ib_mad_send_wr_private *mad_send_wr,
 			  u32 timeout_ms, u32 retries_left);
 
@@ -602,6 +605,7 @@ static void sa_cc_destroy(struct sa_cc_data *cc_obj)
 	}
 	tf_free(cc_obj->tf);
 }
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 /*
  * Returns a ib_mad_port_private structure or NULL for a device/port
@@ -820,11 +824,21 @@ struct ib_mad_agent *ib_register_mad_agent(struct ib_device *device,
 	}
 
 	if (mad_reg_req) {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		reg_req = kmemdup(mad_reg_req, sizeof *reg_req, GFP_KERNEL);
 		if (!reg_req) {
 			ret = ERR_PTR(-ENOMEM);
 			goto error3;
 		}
+#else
+		reg_req = kmalloc(sizeof *reg_req, GFP_KERNEL);
+		if (!reg_req) {
+			ret = ERR_PTR(-ENOMEM);
+			goto error3;
+		}
+		/* Make a copy of the MAD registration request */
+		memcpy(reg_req, mad_reg_req, sizeof *reg_req);
+#endif
 	}
 
 	/* Now, fill in the various structures */
@@ -941,14 +955,28 @@ static int register_snoop_agent(struct ib_mad_qp_info *qp_info,
 
 	if (i == qp_info->snoop_table_size) {
 		/* Grow table. */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		new_snoop_table = krealloc(qp_info->snoop_table,
 					   sizeof mad_snoop_priv *
 					   (qp_info->snoop_table_size + 1),
 					   GFP_ATOMIC);
+#else
+		new_snoop_table = kmalloc(sizeof mad_snoop_priv *
+					  (qp_info->snoop_table_size + 1),
+					  GFP_ATOMIC);
+#endif
 		if (!new_snoop_table) {
 			i = -ENOMEM;
 			goto out;
 		}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+		if (qp_info->snoop_table) {
+			memcpy(new_snoop_table, qp_info->snoop_table,
+			       sizeof mad_snoop_priv *
+			       qp_info->snoop_table_size);
+			kfree(qp_info->snoop_table);
+		}
+#endif
 
 		qp_info->snoop_table = new_snoop_table;
 		qp_info->snoop_table_size++;
@@ -1592,6 +1620,7 @@ dma1_err:
 	return ret;
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 /*
  * Send SA MAD that passed congestion control
  */
@@ -1625,6 +1654,7 @@ static int send_sa_cc_mad(struct ib_mad_send_wr_private *mad_send_wr,
 
 	return ret;
 }
+#endif
 
 /*
  * ib_post_send_mad - Posts MAD(s) to the send queue of the QP associated
@@ -1689,6 +1719,7 @@ int ib_post_send_mad(struct ib_mad_send_buf *send_buf,
 		mad_send_wr->refcount = 1 + (mad_send_wr->timeout > 0);
 		mad_send_wr->status = IB_WC_SUCCESS;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		if (is_sa_cc_mad(mad_send_wr)) {
 			mad_send_wr->is_sa_cc_mad = 1;
 			ret = sa_cc_mad_send(mad_send_wr);
@@ -1717,6 +1748,29 @@ int ib_post_send_mad(struct ib_mad_send_buf *send_buf,
 				goto error;
 			}
 		}
+#else
+		/* Reference MAD agent until send completes */
+		atomic_inc(&mad_agent_priv->refcount);
+		spin_lock_irqsave(&mad_agent_priv->lock, flags);
+		list_add_tail(&mad_send_wr->agent_list,
+			      &mad_agent_priv->send_list);
+		spin_unlock_irqrestore(&mad_agent_priv->lock, flags);
+
+		if (mad_agent_priv->agent.rmpp_version) {
+			ret = ib_send_rmpp_mad(mad_send_wr);
+			if (ret >= 0 && ret != IB_RMPP_RESULT_CONSUMED)
+				ret = ib_send_mad(mad_send_wr);
+		} else
+			ret = ib_send_mad(mad_send_wr);
+		if (ret < 0) {
+			/* Fail send request */
+			spin_lock_irqsave(&mad_agent_priv->lock, flags);
+			list_del(&mad_send_wr->agent_list);
+			spin_unlock_irqrestore(&mad_agent_priv->lock, flags);
+			atomic_dec(&mad_agent_priv->refcount);
+			goto error;
+		}
+#endif
 	}
 	return 0;
 error:
@@ -1777,7 +1831,14 @@ static int method_in_use(struct ib_mad_mgmt_method_table **method,
 {
 	int i;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS) {
+#else
+	for (i = find_first_bit(mad_reg_req->method_mask, IB_MGMT_MAX_METHODS);
+	     i < IB_MGMT_MAX_METHODS;
+	     i = find_next_bit(mad_reg_req->method_mask, IB_MGMT_MAX_METHODS,
+			       1+i)) {
+#endif
 		if ((*method)->agent[i]) {
 			printk(KERN_ERR PFX "Method %d already in use\n", i);
 			return -EINVAL;
@@ -1911,8 +1972,18 @@ static int add_nonoui_reg_req(struct ib_mad_reg_req *mad_reg_req,
 		goto error3;
 
 	/* Finally, add in methods being registered */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS)
 		(*method)->agent[i] = agent_priv;
+#else
+	for (i = find_first_bit(mad_reg_req->method_mask,
+				IB_MGMT_MAX_METHODS);
+	     i < IB_MGMT_MAX_METHODS;
+	     i = find_next_bit(mad_reg_req->method_mask, IB_MGMT_MAX_METHODS,
+			       1+i)) {
+		(*method)->agent[i] = agent_priv;
+	}
+#endif
 
 	return 0;
 
@@ -2006,8 +2077,18 @@ check_in_use:
 		goto error4;
 
 	/* Finally, add in methods being registered */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS)
 		(*method)->agent[i] = agent_priv;
+#else
+	for (i = find_first_bit(mad_reg_req->method_mask,
+				IB_MGMT_MAX_METHODS);
+	     i < IB_MGMT_MAX_METHODS;
+	     i = find_next_bit(mad_reg_req->method_mask, IB_MGMT_MAX_METHODS,
+			       1+i)) {
+		(*method)->agent[i] = agent_priv;
+	}
+#endif
 
 	return 0;
 
@@ -2590,11 +2671,20 @@ static void adjust_timeout(struct ib_mad_agent_private *mad_agent_priv)
 		if (time_after(mad_agent_priv->timeout,
 			       mad_send_wr->timeout)) {
 			mad_agent_priv->timeout = mad_send_wr->timeout;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+			cancel_delayed_work(&mad_agent_priv->timed_work);
+#endif
 			delay = mad_send_wr->timeout - jiffies;
 			if ((long)delay <= 0)
 				delay = 1;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 			mod_delayed_work(mad_agent_priv->qp_info->port_priv->wq,
 					 &mad_agent_priv->timed_work, delay);
+#else
+			queue_delayed_work(mad_agent_priv->qp_info->
+					   port_priv->wq,
+					   &mad_agent_priv->timed_work, delay);
+#endif
 		}
 	}
 }
@@ -2627,9 +2717,17 @@ static void wait_for_response(struct ib_mad_send_wr_private *mad_send_wr)
 	list_add(&mad_send_wr->agent_list, list_item);
 
 	/* Reschedule a work item if we have a shorter timeout */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (mad_agent_priv->wait_list.next == &mad_send_wr->agent_list)
 		mod_delayed_work(mad_agent_priv->qp_info->port_priv->wq,
 				 &mad_agent_priv->timed_work, delay);
+#else
+	if (mad_agent_priv->wait_list.next == &mad_send_wr->agent_list) {
+		cancel_delayed_work(&mad_agent_priv->timed_work);
+		queue_delayed_work(mad_agent_priv->qp_info->port_priv->wq,
+				   &mad_agent_priv->timed_work, delay);
+	}
+#endif
 }
 
 void ib_reset_mad_timeout(struct ib_mad_send_wr_private *mad_send_wr,
@@ -2682,8 +2780,10 @@ void ib_mad_complete_send_wr(struct ib_mad_send_wr_private *mad_send_wr,
 	if (ret == IB_RMPP_RESULT_INTERNAL)
 		ib_rmpp_send_handler(mad_send_wc);
 	else {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		if (mad_send_wr->is_sa_cc_mad)
 			sa_cc_mad_done(get_cc_obj(mad_send_wr));
+#endif
 		mad_agent_priv->agent.send_handler(&mad_agent_priv->agent,
 						   mad_send_wc);
 	}
@@ -2866,7 +2966,9 @@ static void cancel_mads(struct ib_mad_agent_private *mad_agent_priv)
 
 	INIT_LIST_HEAD(&cancel_list);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	cancel_sa_cc_mads(mad_agent_priv);
+#endif
 	spin_lock_irqsave(&mad_agent_priv->lock, flags);
 	list_for_each_entry_safe(mad_send_wr, temp_mad_send_wr,
 				 &mad_agent_priv->send_list, agent_list) {
@@ -2888,8 +2990,10 @@ static void cancel_mads(struct ib_mad_agent_private *mad_agent_priv)
 				 &cancel_list, agent_list) {
 		mad_send_wc.send_buf = &mad_send_wr->send_buf;
 		list_del(&mad_send_wr->agent_list);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		if (mad_send_wr->is_sa_cc_mad)
 			sa_cc_mad_done(get_cc_obj(mad_send_wr));
+#endif
 		mad_agent_priv->agent.send_handler(&mad_agent_priv->agent,
 						   &mad_send_wc);
 		atomic_dec(&mad_agent_priv->refcount);
@@ -2929,6 +3033,7 @@ int ib_modify_mad(struct ib_mad_agent *mad_agent,
 				      agent);
 	spin_lock_irqsave(&mad_agent_priv->lock, flags);
 	mad_send_wr = find_send_wr(mad_agent_priv, send_buf);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (!mad_send_wr) {
 		spin_unlock_irqrestore(&mad_agent_priv->lock, flags);
 		if (modify_sa_cc_mad(mad_agent_priv, send_buf, timeout_ms))
@@ -2939,6 +3044,12 @@ int ib_modify_mad(struct ib_mad_agent *mad_agent,
 		spin_unlock_irqrestore(&mad_agent_priv->lock, flags);
 		return -EINVAL;
 	}
+#else
+	if (!mad_send_wr || mad_send_wr->status != IB_WC_SUCCESS) {
+		spin_unlock_irqrestore(&mad_agent_priv->lock, flags);
+		return -EINVAL;
+	}
+#endif
 
 	active = (!mad_send_wr->timeout || mad_send_wr->refcount > 1);
 	if (!timeout_ms) {
@@ -3119,8 +3230,10 @@ static void timeout_sends(struct work_struct *work)
 		else
 			mad_send_wc.status = mad_send_wr->status;
 		mad_send_wc.send_buf = &mad_send_wr->send_buf;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		if (mad_send_wr->is_sa_cc_mad)
 			sa_cc_mad_done(get_cc_obj(mad_send_wr));
+#endif
 		mad_agent_priv->agent.send_handler(&mad_agent_priv->agent,
 						   &mad_send_wc);
 
@@ -3481,8 +3594,10 @@ static int ib_mad_port_open(struct ib_device *device,
 	}
 	INIT_WORK(&port_priv->work, ib_mad_completion_handler);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (sa_cc_init(&port_priv->sa_cc))
 		goto error9;
+#endif
 
 
 	spin_lock_irqsave(&ib_mad_port_list_lock, flags);
@@ -3503,8 +3618,10 @@ error10:
 	spin_unlock_irqrestore(&ib_mad_port_list_lock, flags);
 
 	destroy_workqueue(port_priv->wq);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 error9:
 	sa_cc_destroy(&port_priv->sa_cc);
+#endif
 error8:
 	destroy_mad_qp(&port_priv->qp_info[1]);
 error7:
@@ -3544,7 +3661,9 @@ static int ib_mad_port_close(struct ib_device *device, int port_num)
 	spin_unlock_irqrestore(&ib_mad_port_list_lock, flags);
 
 	destroy_workqueue(port_priv->wq);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	sa_cc_destroy(&port_priv->sa_cc);
+#endif
 	destroy_mad_qp(&port_priv->qp_info[1]);
 	destroy_mad_qp(&port_priv->qp_info[0]);
 	ib_dereg_mr(port_priv->mr);
@@ -3650,6 +3769,9 @@ static int __init ib_mad_init_module(void)
 	mad_sendq_size = min(mad_sendq_size, IB_MAD_QP_MAX_SIZE);
 	mad_sendq_size = max(mad_sendq_size, IB_MAD_QP_MIN_SIZE);
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+	spin_lock_init(&ib_mad_port_list_lock);
+#endif
 	ib_mad_cache = kmem_cache_create("ib_mad",
 					 sizeof(struct ib_mad_private),
 					 0,
diff --git a/drivers/infiniband/core/netlink.c b/drivers/infiniband/core/netlink.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/netlink.c
+++ b/drivers/infiniband/core/netlink.c
@@ -30,6 +30,7 @@
  * SOFTWARE.
  */
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #ifdef pr_fmt
 #undef pr_fmt
 #endif
@@ -220,3 +221,4 @@ void ibnl_cleanup(void)
 
 	netlink_kernel_release(nls);
 }
+#endif
diff --git a/drivers/infiniband/core/peer_mem.c b/drivers/infiniband/core/peer_mem.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/peer_mem.c
+++ b/drivers/infiniband/core/peer_mem.c
@@ -30,6 +30,7 @@
  * SOFTWARE.
  */
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #include <rdma/ib_peer_mem.h>
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_umem.h>
@@ -122,7 +123,6 @@ static struct attribute *peer_mem_attrs[] = {
 			NULL,
 };
 
-
 static void destroy_peer_sysfs(struct ib_peer_memory_client *ib_peer_client)
 {
 	kobject_put(ib_peer_client->kobj);
@@ -396,7 +396,6 @@ found:
 
 	mutex_unlock(&peer_memory_mutex);
 	return ib_peer_client;
-
 }
 EXPORT_SYMBOL(ib_get_peer_client);
 
@@ -412,4 +411,4 @@ void ib_put_peer_client(struct ib_peer_memory_client *ib_peer_client,
 	return;
 }
 EXPORT_SYMBOL(ib_put_peer_client);
-
+#endif
diff --git a/drivers/infiniband/core/sysfs.c b/drivers/infiniband/core/sysfs.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/sysfs.c
+++ b/drivers/infiniband/core/sysfs.c
@@ -479,6 +479,7 @@ static struct kobj_type port_type = {
 	.default_attrs = port_default_attrs
 };
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static void ib_device_release(struct device *device)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
@@ -500,6 +501,32 @@ static int ib_device_uevent(struct device *device,
 
 	return 0;
 }
+#else
+static void ib_device_release(struct class_device *cdev)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+
+	kfree(dev);
+}
+
+static int ib_device_uevent(struct class_device *cdev, char **envp,
+			    int num_envp, char *buf, int size)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+	int i = 0, len = 0;
+
+	if (add_uevent_var(envp, num_envp, &i, buf, size, &len,
+			   "NAME=%s", dev->name))
+		return -ENOMEM;
+
+	/*
+	 * It would be nice to pass the node GUID with the event...
+	 */
+
+	envp[i] = NULL;
+	return 0;
+}
+#endif
 
 static struct attribute **
 alloc_group_attrs(ssize_t (*show)(struct ib_port *,
@@ -530,7 +557,9 @@ alloc_group_attrs(ssize_t (*show)(struct ib_port *,
 		element->attr.attr.mode  = S_IRUGO;
 		element->attr.show       = show;
 		element->index		 = i;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		sysfs_attr_init(&element->attr.attr);
+#endif
 
 		tab_attr[i] = &element->attr.attr;
 	}
@@ -638,10 +667,16 @@ err_put:
 	return ret;
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_node_type(struct device *device,
 			      struct device_attribute *attr, char *buf)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
+#else
+static ssize_t show_node_type(struct class_device *cdev, char *buf)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+#endif
 
 	switch (dev->node_type) {
 	case RDMA_NODE_IB_CA:	  return sprintf(buf, "%d: CA\n", dev->node_type);
@@ -653,10 +688,16 @@ static ssize_t show_node_type(struct device *device,
 	}
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_sys_image_guid(struct device *device,
 				   struct device_attribute *dev_attr, char *buf)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
+#else
+static ssize_t show_sys_image_guid(struct class_device *cdev, char *buf)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+#endif
 	struct ib_device_attr attr;
 	ssize_t ret;
 
@@ -671,10 +712,16 @@ static ssize_t show_sys_image_guid(struct device *device,
 		       be16_to_cpu(((__be16 *) &attr.sys_image_guid)[3]));
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_node_guid(struct device *device,
 			      struct device_attribute *attr, char *buf)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
+#else
+static ssize_t show_node_guid(struct class_device *cdev, char *buf)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+#endif
 
 	return sprintf(buf, "%04x:%04x:%04x:%04x\n",
 		       be16_to_cpu(((__be16 *) &dev->node_guid)[0]),
@@ -683,19 +730,32 @@ static ssize_t show_node_guid(struct device *device,
 		       be16_to_cpu(((__be16 *) &dev->node_guid)[3]));
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_node_desc(struct device *device,
 			      struct device_attribute *attr, char *buf)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
+#else
+static ssize_t show_node_desc(struct class_device *cdev, char *buf)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+#endif
 
 	return sprintf(buf, "%.64s\n", dev->node_desc);
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t set_node_desc(struct device *device,
 			     struct device_attribute *attr,
 			     const char *buf, size_t count)
 {
 	struct ib_device *dev = container_of(device, struct ib_device, dev);
+#else
+static ssize_t set_node_desc(struct class_device *cdev, const char *buf,
+			      size_t count)
+{
+	struct ib_device *dev = container_of(cdev, struct ib_device, class_dev);
+#endif
 	struct ib_device_modify desc = {};
 	int ret;
 
@@ -710,6 +770,7 @@ static ssize_t set_node_desc(struct device *device,
 	return count;
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_cmd_perf(struct device *device,
 			     struct device_attribute *attr, char *buf)
 {
@@ -762,7 +823,9 @@ static ssize_t show_cmd_n(struct device *device,
 
 	return sprintf(buf, "%d\n", dev->cmd_n);
 }
+#endif
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static DEVICE_ATTR(node_type, S_IRUGO, show_node_type, NULL);
 static DEVICE_ATTR(sys_image_guid, S_IRUGO, show_sys_image_guid, NULL);
 static DEVICE_ATTR(node_guid, S_IRUGO, show_node_guid, NULL);
@@ -786,6 +849,25 @@ static struct class ib_class = {
 	.dev_release = ib_device_release,
 	.dev_uevent = ib_device_uevent,
 };
+#else
+static CLASS_DEVICE_ATTR(node_type, S_IRUGO, show_node_type, NULL);
+static CLASS_DEVICE_ATTR(sys_image_guid, S_IRUGO, show_sys_image_guid, NULL);
+static CLASS_DEVICE_ATTR(node_guid, S_IRUGO, show_node_guid, NULL);
+static CLASS_DEVICE_ATTR(node_desc, S_IRUGO | S_IWUSR, show_node_desc, set_node_desc);
+
+static struct class_device_attribute *ib_class_attributes[] = {
+	&class_device_attr_node_type,
+	&class_device_attr_sys_image_guid,
+	&class_device_attr_node_guid,
+	&class_device_attr_node_desc
+};
+
+static struct class ib_class = {
+	.name    = "infiniband",
+	.release = ib_device_release,
+	.uevent = ib_device_uevent,
+};
+#endif
 
 /* Show a given an attribute in the statistics group */
 static ssize_t show_protocol_stat(const struct device *device,
@@ -905,6 +987,7 @@ int ib_device_register_sysfs(struct ib_device *device,
 			     int (*port_callback)(struct ib_device *,
 						  u8, struct kobject *))
 {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct device *class_dev = &device->dev;
 	int ret;
 	int i;
@@ -925,6 +1008,28 @@ int ib_device_register_sysfs(struct ib_device *device,
 		if (ret)
 			goto err_unregister;
 	}
+#else
+	struct class_device *class_dev = &device->class_dev;
+	int ret;
+	int i;
+
+	class_dev->class      = &ib_class;
+	class_dev->class_data = device;
+	class_dev->dev	      = device->dma_device;
+	strlcpy(class_dev->class_id, device->name, BUS_ID_SIZE);
+
+	INIT_LIST_HEAD(&device->port_list);
+
+	ret = class_device_register(class_dev);
+	if (ret)
+		goto err;
+
+	for (i = 0; i < ARRAY_SIZE(ib_class_attributes); ++i) {
+		ret = class_device_create_file(class_dev, ib_class_attributes[i]);
+		if (ret)
+			goto err_unregister;
+	}
+#endif
 
 	device->ports_parent = kobject_create_and_add("ports",
 					kobject_get(&class_dev->kobj));
@@ -964,14 +1069,26 @@ err_put:
 			sysfs_remove_group(p, &pma_group);
 			sysfs_remove_group(p, &port->pkey_group);
 			sysfs_remove_group(p, &port->gid_group);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 			kobject_put(p);
+#else
+			kobject_unregister(p);
+#endif
 		}
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	kobject_put(&class_dev->kobj);
+#else
+	kobject_unregister(&class_dev->kobj);
+#endif
 
 err_unregister:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	device_unregister(class_dev);
+#else
+	class_device_unregister(class_dev);
+#endif
 
 err:
 	return ret;
@@ -982,8 +1099,10 @@ void ib_device_unregister_sysfs(struct ib_device *device)
 	struct kobject *p, *t;
 	struct ib_port *port;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	/* Hold kobject until ib_dealloc_device() */
 	kobject_get(&device->dev.kobj);
+#endif
 
 	list_for_each_entry_safe(p, t, &device->port_list, entry) {
 		list_del(&p->entry);
@@ -991,11 +1110,21 @@ void ib_device_unregister_sysfs(struct ib_device *device)
 		sysfs_remove_group(p, &pma_group);
 		sysfs_remove_group(p, &port->pkey_group);
 		sysfs_remove_group(p, &port->gid_group);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		kobject_put(p);
+#else
+		kobject_unregister(p);
+#endif
 	}
 
 	kobject_put(device->ports_parent);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	device_unregister(&device->dev);
+#else
+	/* WA for memory leak */
+	kfree(device->ports_parent);
+	class_device_unregister(&device->class_dev);
+#endif
 }
 
 int ib_sysfs_setup(void)
diff --git a/drivers/infiniband/core/ucm.c b/drivers/infiniband/core/ucm.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/ucm.c
+++ b/drivers/infiniband/core/ucm.c
@@ -58,8 +58,13 @@ MODULE_LICENSE("Dual BSD/GPL");
 
 struct ib_ucm_device {
 	int			devnum;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct cdev		cdev;
 	struct device		dev;
+#else
+	struct cdev		dev;
+	struct class_device	class_dev;
+#endif
 	struct ib_device	*ib_dev;
 };
 
@@ -106,6 +111,10 @@ enum {
 	IB_UCM_MAX_DEVICES = 32
 };
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+/* ib_cm and ib_user_cm modules share /sys/class/infiniband_cm */
+extern struct class cm_class;
+#endif
 #define IB_UCM_BASE_DEV MKDEV(IB_UCM_MAJOR, IB_UCM_BASE_MINOR)
 
 static void ib_ucm_add_one(struct ib_device *device);
@@ -397,6 +406,9 @@ static ssize_t ib_ucm_event(struct ib_ucm_file *file,
 	struct ib_ucm_event_get cmd;
 	struct ib_ucm_event *uevent;
 	int result = 0;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+	DEFINE_WAIT(wait);
+#endif
 
 	if (out_len < sizeof(struct ib_ucm_event_resp))
 		return -ENOSPC;
@@ -702,9 +714,20 @@ static int ib_ucm_alloc_data(const void **dest, u64 src, u32 len)
 	if (!len)
 		return 0;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	data = memdup_user((void __user *)(unsigned long)src, len);
 	if (IS_ERR(data))
 		return PTR_ERR(data);
+#else
+	data = kmalloc(len, GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	if (copy_from_user(data, (void __user *)(unsigned long)src, len)) {
+		kfree(data);
+		return -EFAULT;
+	}
+#endif
 
 	*dest = data;
 	return 0;
@@ -1170,9 +1193,15 @@ static int ib_ucm_open(struct inode *inode, struct file *filp)
 
 	filp->private_data = file;
 	file->filp = filp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	file->device = container_of(inode->i_cdev, struct ib_ucm_device, cdev);
 
 	return nonseekable_open(inode, filp);
+#else
+	file->device = container_of(inode->i_cdev, struct ib_ucm_device, dev);
+
+	return 0;
+#endif
 }
 
 static int ib_ucm_close(struct inode *inode, struct file *filp)
@@ -1201,6 +1230,7 @@ static int ib_ucm_close(struct inode *inode, struct file *filp)
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static void ib_ucm_release_dev(struct device *dev)
 {
 	struct ib_ucm_device *ucm_dev;
@@ -1328,6 +1358,96 @@ static void ib_ucm_remove_one(struct ib_device *device)
 
 	device_unregister(&ucm_dev->dev);
 }
+#else /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
+static void ucm_release_class_dev(struct class_device *class_dev)
+{
+	struct ib_ucm_device *dev;
+
+	dev = container_of(class_dev, struct ib_ucm_device, class_dev);
+	cdev_del(&dev->dev);
+	clear_bit(dev->devnum, dev_map);
+	kfree(dev);
+}
+
+static const struct file_operations ucm_fops = {
+	.owner 	 = THIS_MODULE,
+	.open 	 = ib_ucm_open,
+	.release = ib_ucm_close,
+	.write 	 = ib_ucm_write,
+	.poll    = ib_ucm_poll,
+};
+
+static ssize_t show_ibdev(struct class_device *class_dev, char *buf)
+{
+	struct ib_ucm_device *dev;
+
+	dev = container_of(class_dev, struct ib_ucm_device, class_dev);
+	return sprintf(buf, "%s\n", dev->ib_dev->name);
+}
+static CLASS_DEVICE_ATTR(ibdev, S_IRUGO, show_ibdev, NULL);
+
+static void ib_ucm_add_one(struct ib_device *device)
+{
+	struct ib_ucm_device *ucm_dev;
+
+	if (!device->alloc_ucontext ||
+	    rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)
+		return;
+
+	ucm_dev = kzalloc(sizeof *ucm_dev, GFP_KERNEL);
+	if (!ucm_dev)
+		return;
+
+	ucm_dev->ib_dev = device;
+
+	ucm_dev->devnum = find_first_zero_bit(dev_map, IB_UCM_MAX_DEVICES);
+	if (ucm_dev->devnum >= IB_UCM_MAX_DEVICES)
+		goto err;
+
+	set_bit(ucm_dev->devnum, dev_map);
+
+	cdev_init(&ucm_dev->dev, &ucm_fops);
+	ucm_dev->dev.owner = THIS_MODULE;
+	kobject_set_name(&ucm_dev->dev.kobj, "ucm%d", ucm_dev->devnum);
+	if (cdev_add(&ucm_dev->dev, IB_UCM_BASE_DEV + ucm_dev->devnum, 1))
+		goto err;
+
+	ucm_dev->class_dev.class = &cm_class;
+	ucm_dev->class_dev.dev = device->dma_device;
+	ucm_dev->class_dev.devt = ucm_dev->dev.dev;
+	ucm_dev->class_dev.release = ucm_release_class_dev;
+	snprintf(ucm_dev->class_dev.class_id, BUS_ID_SIZE, "ucm%d",
+		 ucm_dev->devnum);
+	if (class_device_register(&ucm_dev->class_dev))
+		goto err_cdev;
+
+	if (class_device_create_file(&ucm_dev->class_dev,
+				     &class_device_attr_ibdev))
+		goto err_class;
+
+	ib_set_client_data(device, &ucm_client, ucm_dev);
+	return;
+
+err_class:
+	class_device_unregister(&ucm_dev->class_dev);
+err_cdev:
+	cdev_del(&ucm_dev->dev);
+	clear_bit(ucm_dev->devnum, dev_map);
+err:
+	kfree(ucm_dev);
+	return;
+}
+
+static void ib_ucm_remove_one(struct ib_device *device)
+{
+	struct ib_ucm_device *ucm_dev = ib_get_client_data(device, &ucm_client);
+
+	if (!ucm_dev)
+		return;
+
+	class_device_unregister(&ucm_dev->class_dev);
+}
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,34))
 static CLASS_ATTR_STRING(abi_version, S_IRUGO,
@@ -1389,8 +1509,10 @@ static void __exit ib_ucm_cleanup(void)
 	class_remove_file(&cm_class, &class_attr_abi_version);
 #endif
 	unregister_chrdev_region(IB_UCM_BASE_DEV, IB_UCM_MAX_DEVICES);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (overflow_maj)
 		unregister_chrdev_region(overflow_maj, IB_UCM_MAX_DEVICES);
+#endif
 	idr_destroy(&ctx_id_table);
 }
 
diff --git a/drivers/infiniband/core/ucma.c b/drivers/infiniband/core/ucma.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/ucma.c
+++ b/drivers/infiniband/core/ucma.c
@@ -54,6 +54,7 @@ MODULE_LICENSE("Dual BSD/GPL");
 
 static unsigned int max_backlog = 1024;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #ifndef CONFIG_SYSCTL_SYSCALL_CHECK
 static struct ctl_table_header *ucma_ctl_table_hdr;
 static ctl_table ucma_ctl_table[] = {
@@ -74,6 +75,7 @@ static struct ctl_path ucma_ctl_path[] = {
 };
 #endif
 #endif
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 struct ucma_file {
 	struct mutex		mut;
@@ -1012,6 +1014,7 @@ static ssize_t ucma_set_option(struct ucma_file *file, const char __user *inbuf,
 	if (IS_ERR(ctx))
 		return PTR_ERR(ctx);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	optval = memdup_user((void __user *) (unsigned long) cmd.optval,
 			     cmd.optlen);
 	if (IS_ERR(optval)) {
@@ -1026,6 +1029,27 @@ static ssize_t ucma_set_option(struct ucma_file *file, const char __user *inbuf,
 out:
 	ucma_put_ctx(ctx);
 	return ret;
+#else
+	optval = kmalloc(cmd.optlen, GFP_KERNEL);
+	if (!optval) {
+		ret = -ENOMEM;
+		goto out1;
+	}
+
+	if (copy_from_user(optval, (void __user *) (unsigned long) cmd.optval,
+			   cmd.optlen)) {
+		ret = -EFAULT;
+		goto out2;
+	}
+
+	ret = ucma_set_option_level(ctx, cmd.level, cmd.optname, optval,
+				    cmd.optlen);
+out2:
+	kfree(optval);
+out1:
+	ucma_put_ctx(ctx);
+	return ret;
+#endif
 }
 
 static ssize_t ucma_notify(struct ucma_file *file, const char __user *inbuf,
@@ -1388,11 +1412,14 @@ static const struct file_operations ucma_fops = {
 static struct miscdevice ucma_misc = {
 	.minor		= MISC_DYNAMIC_MINOR,
 	.name		= "rdma_cm",
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	.nodename	= "infiniband/rdma_cm",
 	.mode		= 0666,
+#endif
 	.fops		= &ucma_fops,
 };
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_abi_version(struct device *dev,
 				struct device_attribute *attr,
 				char *buf)
@@ -1400,6 +1427,13 @@ static ssize_t show_abi_version(struct device *dev,
 	return sprintf(buf, "%d\n", RDMA_USER_CM_ABI_VERSION);
 }
 static DEVICE_ATTR(abi_version, S_IRUGO, show_abi_version, NULL);
+#else
+static ssize_t show_abi_version(struct class_device *class_dev, char *buf)
+{
+	return sprintf(buf, "%d\n", RDMA_USER_CM_ABI_VERSION);
+}
+static CLASS_DEVICE_ATTR(abi_version, S_IRUGO, show_abi_version, NULL);
+#endif
 
 static int __init ucma_init(void)
 {
@@ -1409,12 +1443,18 @@ static int __init ucma_init(void)
 	if (ret)
 		return ret;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	ret = device_create_file(ucma_misc.this_device, &dev_attr_abi_version);
+#else
+	ret = class_device_create_file(ucma_misc.class,
+				       &class_device_attr_abi_version);
+#endif
 	if (ret) {
 		printk(KERN_ERR "rdma_ucm: couldn't create abi_version attr\n");
 		goto err1;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #ifndef CONFIG_SYSCTL_SYSCALL_CHECK
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,5,0)
 	ucma_ctl_table_hdr = register_net_sysctl(&init_net, "net/rdma_ucm", ucma_ctl_table);
@@ -1432,6 +1472,9 @@ static int __init ucma_init(void)
 err2:
 	device_remove_file(ucma_misc.this_device, &dev_attr_abi_version);
 #endif
+#else
+	return 0;
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 err1:
 	misc_deregister(&ucma_misc);
 	return ret;
@@ -1439,6 +1482,7 @@ err1:
 
 static void __exit ucma_cleanup(void)
 {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #ifndef CONFIG_SYSCTL_SYSCALL_CHECK
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,5,0)
 	unregister_net_sysctl_table(ucma_ctl_table_hdr);
@@ -1447,6 +1491,10 @@ static void __exit ucma_cleanup(void)
 #endif
 #endif
 	device_remove_file(ucma_misc.this_device, &dev_attr_abi_version);
+#else
+	class_device_remove_file(ucma_misc.class,
+				 &class_device_attr_abi_version);
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 	misc_deregister(&ucma_misc);
 	idr_destroy(&ctx_idr);
 }
diff --git a/drivers/infiniband/core/umem.c b/drivers/infiniband/core/umem.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/umem.c
+++ b/drivers/infiniband/core/umem.c
@@ -42,6 +42,7 @@
 #include <linux/module.h>
 #include "uverbs.h"
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static int allow_weak_ordering;
 module_param_named(weak_ordering, allow_weak_ordering, int, 0444);
 MODULE_PARM_DESC(weak_ordering,  "Allow weak ordering for data registered memory");
@@ -557,6 +558,7 @@ static void peer_umem_release(struct ib_umem *umem)
 	return;
 
 }
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 static void __ib_umem_release(struct ib_device *dev, struct ib_umem *umem, int dirty)
 {
@@ -582,6 +584,7 @@ static void __ib_umem_release(struct ib_device *dev, struct ib_umem *umem, int d
 
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 void ib_umem_activate_invalidation_notifier(struct ib_umem *umem,
 					       umem_invalidate_func_t func,
 					       void *cookie)
@@ -596,6 +599,7 @@ void ib_umem_activate_invalidation_notifier(struct ib_umem *umem,
 	return;
 }
 EXPORT_SYMBOL(ib_umem_activate_invalidation_notifier);
+#endif
 /**
  * ib_umem_get - Pin and DMA map userspace memory.
  * @context: userspace context to pin memory for
@@ -623,9 +627,11 @@ struct ib_umem *ib_umem_get_ex(struct ib_ucontext *context, unsigned long addr,
 
 	if (dmasync)
 		dma_set_attr(DMA_ATTR_WRITE_BARRIER, &attrs);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	else if (allow_weak_ordering)
 		dma_set_attr(DMA_ATTR_WEAK_ORDERING, &attrs);
 
+#endif
 
 	if (!can_do_mlock())
 		return ERR_PTR(-EPERM);
@@ -646,6 +652,7 @@ struct ib_umem *ib_umem_get_ex(struct ib_ucontext *context, unsigned long addr,
 	 * "MW bind" can change permissions by binding a window.
 	 */
 	umem->writable  = !!(access & ~IB_ACCESS_REMOTE_READ);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (invalidation_supported || context->peer_mem_private_data) {
 
 		struct ib_peer_memory_client *peer_mem_client;
@@ -657,6 +664,7 @@ struct ib_umem *ib_umem_get_ex(struct ib_ucontext *context, unsigned long addr,
 			return peer_umem_get(peer_mem_client, umem, addr,
 					dmasync, invalidation_supported);
 	}
+#endif
 
 	/* We assume the memory is from hugetlb until proved otherwise */
 	umem->hugetlb   = 1;
@@ -684,7 +692,11 @@ struct ib_umem *ib_umem_get_ex(struct ib_ucontext *context, unsigned long addr,
 #else
 	locked     = npages + current->mm->locked_vm;
 #endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	lock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;
+#else
+	lock_limit = current->signal->rlim[RLIMIT_MEMLOCK].rlim_cur >> PAGE_SHIFT;
+#endif
 
 	if ((locked > lock_limit) && !capable(CAP_IPC_LOCK)) {
 		ret = -ENOMEM;
@@ -794,10 +806,12 @@ void ib_umem_release(struct ib_umem *umem)
 	struct ib_ucontext *context = umem->context;
 	struct mm_struct *mm;
 	unsigned long diff;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (umem->ib_peer_mem) {
 		peer_umem_release(umem);
 		return;
 	}
+#endif
 
 	__ib_umem_release(umem->context->device, umem, 1);
 
@@ -823,7 +837,11 @@ void ib_umem_release(struct ib_umem *umem)
 			umem->mm   = mm;
 			umem->diff = diff;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 			queue_work(ib_wq, &umem->work);
+#else
+			schedule_work(&umem->work);
+#endif
 			return;
 		}
 	} else
diff --git a/drivers/infiniband/core/user_mad.c b/drivers/infiniband/core/user_mad.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/user_mad.c
+++ b/drivers/infiniband/core/user_mad.c
@@ -80,11 +80,19 @@ enum {
  */
 
 struct ib_umad_port {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct cdev           *cdev;
 	struct device	      *dev;
 
 	struct cdev           *sm_cdev;
 	struct device	      *sm_dev;
+#else
+	struct cdev           *dev;
+	struct class_device   *class_dev;
+
+	struct cdev           *sm_dev;
+	struct class_device   *sm_class_dev;
+#endif
 	struct semaphore       sm_sem;
 
 	struct mutex	       file_mutex;
@@ -94,7 +102,9 @@ struct ib_umad_port {
 	struct ib_umad_device *umad_dev;
 	int                    dev_num;
 	u8                     port_num;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct list_head       port_lst;
+#endif
 };
 
 struct ib_umad_device {
@@ -130,12 +140,18 @@ static struct class *umad_class;
 static const dev_t base_dev = MKDEV(IB_UMAD_MAJOR, IB_UMAD_MINOR_BASE);
 
 static DEFINE_SPINLOCK(port_lock);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+static struct ib_umad_port *umad_port[IB_UMAD_MAX_PORTS];
+#endif
 static DECLARE_BITMAP(dev_map, IB_UMAD_MAX_PORTS);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static DECLARE_BITMAP(overflow_map, IB_UMAD_MAX_PORTS);
+#endif
 
 static void ib_umad_add_one(struct ib_device *device);
 static void ib_umad_remove_one(struct ib_device *device);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static DEFINE_SPINLOCK(ports_list_lock);
 static struct list_head ports_list;
 
@@ -210,6 +226,15 @@ static void insert_port(struct ib_umad_port *port)
 	list_add(&port->port_lst, &ports_list);
 	spin_unlock(&ports_list_lock);
 }
+#else
+static void ib_umad_release_dev(struct kref *ref)
+{
+	struct ib_umad_device *dev =
+		container_of(ref, struct ib_umad_device, ref);
+
+	kfree(dev);
+}
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */ 
 
 static int hdr_size(struct ib_umad_file *file)
 {
@@ -849,6 +874,7 @@ static int ib_umad_open(struct inode *inode, struct file *filp)
 {
 	struct ib_umad_port *port;
 	struct ib_umad_file *file;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	int ret;
 
 	port = get_port(inode->i_cdev);
@@ -883,6 +909,44 @@ static int ib_umad_open(struct inode *inode, struct file *filp)
 
 	ret = nonseekable_open(inode, filp);
 
+#else
+	int ret = 0;
+
+	spin_lock(&port_lock);
+	port = umad_port[iminor(inode) - IB_UMAD_MINOR_BASE];
+	if (port)
+		kref_get(&port->umad_dev->ref);
+	spin_unlock(&port_lock);
+
+	if (!port)
+		return -ENXIO;
+
+	mutex_lock(&port->file_mutex);
+
+	if (!port->ib_dev) {
+		ret = -ENXIO;
+		goto out;
+	}
+
+	file = kzalloc(sizeof *file, GFP_KERNEL);
+	if (!file) {
+		kref_put(&port->umad_dev->ref, ib_umad_release_dev);
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	mutex_init(&file->mutex);
+	spin_lock_init(&file->send_lock);
+	INIT_LIST_HEAD(&file->recv_list);
+	INIT_LIST_HEAD(&file->send_list);
+	init_waitqueue_head(&file->recv_wait);
+
+	file->port = port;
+	filp->private_data = file;
+
+	list_add_tail(&file->port_list, &port->file_list);
+
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 out:
 	mutex_unlock(&port->file_mutex);
 	return ret;
@@ -891,7 +955,11 @@ out:
 static int ib_umad_close(struct inode *inode, struct file *filp)
 {
 	struct ib_umad_file *file = filp->private_data;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct ib_umad_port *port = file->port;
+#else
+	struct ib_umad_device *dev = file->port->umad_dev;
+#endif
 	struct ib_umad_packet *packet, *tmp;
 	int already_dead;
 	int i;
@@ -920,7 +988,11 @@ static int ib_umad_close(struct inode *inode, struct file *filp)
 	mutex_unlock(&file->port->file_mutex);
 
 	kfree(file);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	release_port(port);
+#else
+	kref_put(&dev->ref, ib_umad_release_dev);
+#endif
 
 	return 0;
 }
@@ -936,7 +1008,9 @@ static const struct file_operations umad_fops = {
 #endif
 	.open		= ib_umad_open,
 	.release	= ib_umad_close,
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	.llseek		= no_llseek,
+#endif
 };
 
 static int ib_umad_sm_open(struct inode *inode, struct file *filp)
@@ -947,7 +1021,15 @@ static int ib_umad_sm_open(struct inode *inode, struct file *filp)
 	};
 	int ret;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	port = get_port(inode->i_cdev);
+#else
+	spin_lock(&port_lock);
+	port = umad_port[iminor(inode) - IB_UMAD_MINOR_BASE - IB_UMAD_MAX_PORTS];
+	if (port)
+		kref_get(&port->umad_dev->ref);
+	spin_unlock(&port_lock);
+#endif
 	if (!port)
 		return -ENXIO;
 
@@ -971,10 +1053,18 @@ static int ib_umad_sm_open(struct inode *inode, struct file *filp)
 
 	filp->private_data = port;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	return nonseekable_open(inode, filp);
+#else
+	return 0;
+#endif
 
 fail:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	release_port(port);
+#else
+	kref_put(&port->umad_dev->ref, ib_umad_release_dev);
+#endif
 	return ret;
 }
 
@@ -993,7 +1083,11 @@ static int ib_umad_sm_close(struct inode *inode, struct file *filp)
 
 	up(&port->sm_sem);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	release_port(port);
+#else
+	kref_put(&port->umad_dev->ref, ib_umad_release_dev);
+#endif
 
 	return ret;
 }
@@ -1011,6 +1105,7 @@ static struct ib_client umad_client = {
 	.remove = ib_umad_remove_one
 };
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_ibdev(struct device *dev, struct device_attribute *attr,
 			  char *buf)
 {
@@ -1034,6 +1129,29 @@ static ssize_t show_port(struct device *dev, struct device_attribute *attr,
 	return sprintf(buf, "%d\n", port->port_num);
 }
 static DEVICE_ATTR(port, S_IRUGO, show_port, NULL);
+#else
+static ssize_t show_ibdev(struct class_device *class_dev, char *buf)
+{
+	struct ib_umad_port *port = class_get_devdata(class_dev);
+
+	if (!port)
+		return -ENODEV;
+
+	return sprintf(buf, "%s\n", port->ib_dev->name);
+}
+static CLASS_DEVICE_ATTR(ibdev, S_IRUGO, show_ibdev, NULL);
+
+static ssize_t show_port(struct class_device *class_dev, char *buf)
+{
+	struct ib_umad_port *port = class_get_devdata(class_dev);
+
+	if (!port)
+		return -ENODEV;
+
+	return sprintf(buf, "%d\n", port->port_num);
+}
+static CLASS_DEVICE_ATTR(port, S_IRUGO, show_port, NULL);
+#endif
 
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,34))
 static CLASS_ATTR_STRING(abi_version, S_IRUGO,
@@ -1046,6 +1164,7 @@ static ssize_t show_abi_version(struct class *class, char *buf)
 static CLASS_ATTR(abi_version, S_IRUGO, show_abi_version, NULL);
 #endif
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static dev_t overflow_maj;
 static int find_overflow_devnum(void)
 {
@@ -1066,10 +1185,12 @@ static int find_overflow_devnum(void)
 
 	return ret;
 }
+#endif
 
 static int ib_umad_init_port(struct ib_device *device, int port_num,
 			     struct ib_umad_port *port)
 {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	int devnum;
 	dev_t base;
 
@@ -1159,6 +1280,84 @@ err_cdev_c:
 		clear_bit(devnum, dev_map);
 	else
 		clear_bit(devnum, overflow_map);
+#else
+	spin_lock(&port_lock);
+	port->dev_num = find_first_zero_bit(dev_map, IB_UMAD_MAX_PORTS);
+	if (port->dev_num >= IB_UMAD_MAX_PORTS) {
+		spin_unlock(&port_lock);
+		return -1;
+	}
+	set_bit(port->dev_num, dev_map);
+	spin_unlock(&port_lock);
+
+	port->ib_dev   = device;
+	port->port_num = port_num;
+	init_MUTEX(&port->sm_sem);
+	mutex_init(&port->file_mutex);
+	INIT_LIST_HEAD(&port->file_list);
+
+	port->dev = cdev_alloc();
+	if (!port->dev)
+		return -1;
+	port->dev->owner = THIS_MODULE;
+	port->dev->ops   = &umad_fops;
+	kobject_set_name(&port->dev->kobj, "umad%d", port->dev_num);
+	if (cdev_add(port->dev, base_dev + port->dev_num, 0))
+		goto err_cdev;
+
+	port->class_dev = class_device_create(umad_class, NULL, port->dev->dev,
+					      device->dma_device,
+					      "umad%d", port->dev_num);
+	if (IS_ERR(port->class_dev))
+		goto err_cdev;
+
+	if (class_device_create_file(port->class_dev, &class_device_attr_ibdev))
+		goto err_class;
+	if (class_device_create_file(port->class_dev, &class_device_attr_port))
+		goto err_class;
+
+	port->sm_dev = cdev_alloc();
+	if (!port->sm_dev)
+		goto err_class;
+	port->sm_dev->owner = THIS_MODULE;
+	port->sm_dev->ops   = &umad_sm_fops;
+	kobject_set_name(&port->sm_dev->kobj, "issm%d", port->dev_num);
+	if (cdev_add(port->sm_dev, base_dev + port->dev_num + IB_UMAD_MAX_PORTS, 1))
+		goto err_sm_cdev;
+
+	port->sm_class_dev = class_device_create(umad_class, NULL, port->sm_dev->dev,
+						 device->dma_device,
+						 "issm%d", port->dev_num);
+	if (IS_ERR(port->sm_class_dev))
+		goto err_sm_cdev;
+
+	class_set_devdata(port->class_dev,    port);
+	class_set_devdata(port->sm_class_dev, port);
+
+	if (class_device_create_file(port->sm_class_dev, &class_device_attr_ibdev))
+		goto err_sm_class;
+	if (class_device_create_file(port->sm_class_dev, &class_device_attr_port))
+		goto err_sm_class;
+
+	spin_lock(&port_lock);
+	umad_port[port->dev_num] = port;
+	spin_unlock(&port_lock);
+
+	return 0;
+
+err_sm_class:
+	class_device_destroy(umad_class, port->sm_dev->dev);
+
+err_sm_cdev:
+	cdev_del(port->sm_dev);
+
+err_class:
+	class_device_destroy(umad_class, port->dev->dev);
+
+err_cdev:
+	cdev_del(port->dev);
+	clear_bit(port->dev_num, dev_map);
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 	return -1;
 }
@@ -1166,6 +1365,7 @@ err_cdev_c:
 static void ib_umad_kill_port(struct ib_umad_port *port)
 {
 	struct ib_umad_file *file;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	int id;
 
 	dev_set_drvdata(port->dev,    NULL);
@@ -1189,6 +1389,42 @@ static void ib_umad_kill_port(struct ib_umad_port *port)
 	}
 
 	mutex_unlock(&port->file_mutex);
+#else
+	int already_dead;
+	int id;
+
+	class_set_devdata(port->class_dev,    NULL);
+	class_set_devdata(port->sm_class_dev, NULL);
+
+	class_device_destroy(umad_class, port->dev->dev);
+	class_device_destroy(umad_class, port->sm_dev->dev);
+
+	cdev_del(port->dev);
+	cdev_del(port->sm_dev);
+
+	spin_lock(&port_lock);
+	umad_port[port->dev_num] = NULL;
+	spin_unlock(&port_lock);
+
+	mutex_lock(&port->file_mutex);
+
+	port->ib_dev = NULL;
+
+	list_for_each_entry(file, &port->file_list, port_list) {
+		mutex_lock(&file->mutex);
+		already_dead = file->agents_dead;
+		file->agents_dead = 1;
+		mutex_unlock(&file->mutex);
+
+		for (id = 0; id < IB_UMAD_MAX_AGENTS; ++id)
+			if (file->agent[id])
+				ib_unregister_mad_agent(file->agent[id]);
+	}
+
+	mutex_unlock(&port->file_mutex);
+
+	clear_bit(port->dev_num, dev_map);
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 }
 
 static void ib_umad_add_one(struct ib_device *device)
@@ -1217,14 +1453,22 @@ static void ib_umad_add_one(struct ib_device *device)
 	umad_dev->start_port = s;
 	umad_dev->end_port   = e;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	for (i = 0; i <= e - s; ++i)
 		insert_port(&umad_dev->port[i]);
 
+#endif
 	for (i = s; i <= e; ++i) {
 		umad_dev->port[i - s].umad_dev = umad_dev;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		if (ib_umad_init_port(device, i, &umad_dev->port[i - s]))
 			goto err;
+#else
+		if (rdma_port_get_link_layer(device, i) == IB_LINK_LAYER_INFINIBAND)
+			if (ib_umad_init_port(device, i, &umad_dev->port[i - s]))
+				goto err;
+#endif
 	}
 
 	ib_set_client_data(device, &umad_client, umad_dev);
@@ -1233,9 +1477,16 @@ static void ib_umad_add_one(struct ib_device *device)
 
 err:
 	while (--i >= s)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		ib_umad_kill_port(&umad_dev->port[i - s]);
 
 	put_umad_dev(&umad_dev->ref);
+#else
+		if (rdma_port_get_link_layer(device, i) == IB_LINK_LAYER_INFINIBAND)
+			ib_umad_kill_port(&umad_dev->port[i - s]);
+
+	kref_put(&umad_dev->ref, ib_umad_release_dev);
+#endif
 }
 
 static void ib_umad_remove_one(struct ib_device *device)
@@ -1247,11 +1498,19 @@ static void ib_umad_remove_one(struct ib_device *device)
 		return;
 
 	for (i = 0; i <= umad_dev->end_port - umad_dev->start_port; ++i)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 		ib_umad_kill_port(&umad_dev->port[i]);
 
 	put_umad_dev(&umad_dev->ref);
+#else
+		if (rdma_port_get_link_layer(device, i + 1) == IB_LINK_LAYER_INFINIBAND)
+			ib_umad_kill_port(&umad_dev->port[i]);
+
+	kref_put(&umad_dev->ref, ib_umad_release_dev);
+#endif
 }
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
 static char *umad_devnode(struct device *dev, umode_t *mode)
 #else
@@ -1260,13 +1519,16 @@ static char *umad_devnode(struct device *dev, mode_t *mode)
 {
 	return kasprintf(GFP_KERNEL, "infiniband/%s", dev_name(dev));
 }
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 static int __init ib_umad_init(void)
 {
 	int ret;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	INIT_LIST_HEAD(&ports_list);
 
+#endif
 	ret = register_chrdev_region(base_dev, IB_UMAD_MAX_PORTS * 2,
 				     "infiniband_mad");
 	if (ret) {
@@ -1281,7 +1543,9 @@ static int __init ib_umad_init(void)
 		goto out_chrdev;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	umad_class->devnode = umad_devnode;
+#endif
 
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,34))
 	ret = class_create_file(umad_class, &class_attr_abi_version.attr);
@@ -1316,8 +1580,10 @@ static void __exit ib_umad_cleanup(void)
 	ib_unregister_client(&umad_client);
 	class_destroy(umad_class);
 	unregister_chrdev_region(base_dev, IB_UMAD_MAX_PORTS * 2);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (overflow_maj)
 		unregister_chrdev_region(overflow_maj, IB_UMAD_MAX_PORTS * 2);
+#endif
 }
 
 module_init(ib_umad_init);
diff --git a/drivers/infiniband/core/uverbs.h b/drivers/infiniband/core/uverbs.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/uverbs.h
+++ b/drivers/infiniband/core/uverbs.h
@@ -74,10 +74,17 @@ struct ib_uverbs_device {
 	struct kref				ref;
 	int					num_comp_vectors;
 	struct completion			comp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct device			       *dev;
+#endif
 	struct ib_device		       *ib_dev;
 	int					devnum;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	struct cdev			        cdev;
+#else
+	struct cdev			       *dev;
+	struct class_device		       *class_dev;
+#endif
 	struct rb_root				xrcd_tree;
 	struct mutex				xrcd_tree_mutex;
 };
diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@ -2099,6 +2099,7 @@ static ssize_t __uverbs_modify_qp(struct ib_uverbs_file *file,
 	attr->alt_ah_attr.static_rate       = cmd.alt_dest.static_rate;
 	attr->alt_ah_attr.ah_flags 	    = cmd.alt_dest.is_global ? IB_AH_GRH : 0;
 	attr->alt_ah_attr.port_num 	    = cmd.alt_dest.port_num;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	port_num = (cmd.attr_mask & IB_QP_PORT) ? cmd.port_num : qp->port_num;
 	if ((cmd.attr_mask & IB_QP_AV) && port_num &&
 	    (rdma_port_get_link_layer(qp->device, port_num) ==
@@ -2142,6 +2143,11 @@ static ssize_t __uverbs_modify_qp(struct ib_uverbs_file *file,
 	} else {
 		ret = ib_modify_qp(qp, attr, modify_qp_mask(qp->qp_type, cmd.attr_mask));
 	}
+#else
+	ret = qp->device->modify_qp(qp, attr, cmd.attr_mask, &udata);
+	if (!ret && (cmd.attr_mask & IB_QP_PORT))
+		qp->port_num = attr->port_num;
+#endif
 
 	if (ret)
 		goto out;
diff --git a/drivers/infiniband/core/uverbs_main.c b/drivers/infiniband/core/uverbs_main.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/uverbs_main.c
+++ b/drivers/infiniband/core/uverbs_main.c
@@ -43,7 +43,9 @@
 #include <linux/sched.h>
 #include <linux/file.h>
 #include <linux/cdev.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #include <linux/anon_inodes.h>
+#endif
 #include <linux/slab.h>
 
 #include <asm/uaccess.h>
@@ -54,6 +56,10 @@ MODULE_AUTHOR("Roland Dreier");
 MODULE_DESCRIPTION("InfiniBand userspace verbs access");
 MODULE_LICENSE("Dual BSD/GPL");
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+#define INFINIBANDEVENTFS_MAGIC	0x49426576	/* "IBev" */
+#endif
+
 enum {
 	IB_UVERBS_MAJOR       = 231,
 	IB_UVERBS_BASE_MINOR  = 192,
@@ -101,7 +107,12 @@ DEFINE_IDR(ib_uverbs_xrcd_idr);
 DEFINE_IDR(ib_uverbs_rule_idr);
 DEFINE_IDR(ib_uverbs_dct_idr);
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static DEFINE_SPINLOCK(map_lock);
+#else
+static spinlock_t map_lock;
+static struct ib_uverbs_device *dev_table[IB_UVERBS_MAX_DEVICES];
+#endif
 static DECLARE_BITMAP(dev_map, IB_UVERBS_MAX_DEVICES);
 
 static ssize_t (*uverbs_cmd_table[])(struct ib_uverbs_file *file,
@@ -163,6 +174,9 @@ static ssize_t (*uverbs_exp_cmd_table[])(struct ib_uverbs_file *file,
 	[IB_USER_VERBS_EXP_CMD_QUERY_DCT]	= ib_uverbs_exp_query_dct,
 };
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+static struct vfsmount *uverbs_event_mnt;
+#endif
 static void ib_uverbs_add_one(struct ib_device *device);
 static void ib_uverbs_remove_one(struct ib_device *device);
 
@@ -602,6 +616,9 @@ struct file *ib_uverbs_alloc_event_file(struct ib_uverbs_file *uverbs_file,
 {
 	struct ib_uverbs_event_file *ev_file;
 	struct file *filp;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+	int ret;
+#endif
 
 	ev_file = kmalloc(sizeof *ev_file, GFP_KERNEL);
 	if (!ev_file)
@@ -616,12 +633,39 @@ struct file *ib_uverbs_alloc_event_file(struct ib_uverbs_file *uverbs_file,
 	ev_file->is_async    = is_async;
 	ev_file->is_closed   = 0;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	filp = anon_inode_getfile("[infinibandevent]", &uverbs_event_fops,
 				  ev_file, O_RDONLY);
 	if (IS_ERR(filp))
 		kfree(ev_file);
 
 	return filp;
+#else
+	filp = get_empty_filp();
+	if (!filp) {
+		ret = -ENFILE;
+		goto err;
+	}
+
+	/*
+	 * fops_get() can't fail here, because we're coming from a
+	 * system call on a uverbs file, which will already have a
+	 * module reference.
+	 */
+	filp->f_op 	   = fops_get(&uverbs_event_fops);
+	filp->f_vfsmnt 	   = mntget(uverbs_event_mnt);
+	filp->f_dentry 	   = dget(uverbs_event_mnt->mnt_root);
+	filp->f_mapping    = filp->f_dentry->d_inode->i_mapping;
+	filp->f_flags      = O_RDONLY;
+	filp->f_mode       = FMODE_READ;
+	filp->private_data = ev_file;
+
+	return filp;
+
+err:
+	kfree(ev_file);
+	return ERR_PTR(ret);
+#endif
 }
 
 /*
@@ -654,9 +698,13 @@ out:
 	return ev_file;
 #else
 	struct file *filp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	int fput_needed;
 
 	filp = fget_light(fd, &fput_needed);
+#else
+	filp = fget(fd);
+#endif
 	if (!filp)
 		return NULL;
 
@@ -672,7 +720,11 @@ out:
 	kref_get(&ev_file->ref);
 
 out:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	fput_light(filp, fput_needed);
+#else
+	fput(filp);
+#endif
 	return ev_file;
 #endif
 }
@@ -1080,11 +1132,22 @@ static int ib_uverbs_open(struct inode *inode, struct file *filp)
 	struct ib_uverbs_file *file;
 	int ret;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	dev = container_of(inode->i_cdev, struct ib_uverbs_device, cdev);
 	if (dev)
 		kref_get(&dev->ref);
 	else
 		return -ENXIO;
+#else
+	spin_lock(&map_lock);
+	dev = dev_table[iminor(inode) - IB_UVERBS_BASE_MINOR];
+	if (dev)
+		kref_get(&dev->ref);
+	spin_unlock(&map_lock);
+
+	if (!dev)
+		return -ENXIO;
+#endif
 
 	if (!try_module_get(dev->ib_dev->owner)) {
 		ret = -ENODEV;
@@ -1155,6 +1218,7 @@ static struct ib_client uverbs_client = {
 	.remove = ib_uverbs_remove_one
 };
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 static ssize_t show_ibdev(struct device *device, struct device_attribute *attr,
 			  char *buf)
 {
@@ -1331,7 +1395,164 @@ static void ib_uverbs_remove_one(struct ib_device *device)
 	wait_for_completion(&uverbs_dev->comp);
 	kfree(uverbs_dev);
 }
+#else /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
+static ssize_t show_ibdev(struct class_device *class_dev, char *buf)
+{
+	struct ib_uverbs_device *dev = class_get_devdata(class_dev);
+
+	if (!dev)
+		return -ENODEV;
+
+	return sprintf(buf, "%s\n", dev->ib_dev->name);
+}
+static CLASS_DEVICE_ATTR(ibdev, S_IRUGO, show_ibdev, NULL);
+
+static ssize_t show_dev_abi_version(struct class_device *class_dev, char *buf)
+{
+	struct ib_uverbs_device *dev = class_get_devdata(class_dev);
+
+	if (!dev)
+		return -ENODEV;
+
+	return sprintf(buf, "%d\n", dev->ib_dev->uverbs_abi_ver);
+}
+static CLASS_DEVICE_ATTR(abi_version, S_IRUGO, show_dev_abi_version, NULL);
+
+static ssize_t show_abi_version(struct class *class, char *buf)
+{
+	return sprintf(buf, "%d\n", IB_USER_VERBS_ABI_VERSION);
+}
+static CLASS_ATTR(abi_version, S_IRUGO, show_abi_version, NULL);
+
+static ssize_t show_dev_ref_cnt(struct class_device *class_dev, char *buf)
+{
+	struct ib_uverbs_device *dev = class_get_devdata(class_dev);
+
+	if (!dev)
+		return -ENODEV;
+
+	return sprintf(buf, "%d\n",  atomic_read(&dev->ref.refcount));
+}
+static CLASS_DEVICE_ATTR(ref_cnt, S_IRUGO, show_dev_ref_cnt, NULL);
+
+static ssize_t show_ref_cnt(struct class *class, char *buf)
+{
+	return sprintf(buf, "%d\n", IB_USER_VERBS_REF_CNT);
+}
+static CLASS_ATTR(ref_cnt, S_IRUGO, show_ref_cnt, NULL);
+
+static void ib_uverbs_add_one(struct ib_device *device)
+{
+	struct ib_uverbs_device *uverbs_dev;
+
+	if (!device->alloc_ucontext)
+		return;
+
+	uverbs_dev = kzalloc(sizeof *uverbs_dev, GFP_KERNEL);
+	if (!uverbs_dev)
+		return;
+
+	kref_init(&uverbs_dev->ref);
+	init_completion(&uverbs_dev->comp);
+
+	spin_lock(&map_lock);
+	uverbs_dev->devnum = find_first_zero_bit(dev_map, IB_UVERBS_MAX_DEVICES);
+	if (uverbs_dev->devnum >= IB_UVERBS_MAX_DEVICES) {
+		spin_unlock(&map_lock);
+		goto err;
+	}
+	set_bit(uverbs_dev->devnum, dev_map);
+	spin_unlock(&map_lock);
+
+	uverbs_dev->ib_dev           = device;
+	uverbs_dev->num_comp_vectors = device->num_comp_vectors;
+
+	uverbs_dev->dev = cdev_alloc();
+	if (!uverbs_dev->dev)
+		goto err;
+	uverbs_dev->dev->owner = THIS_MODULE;
+	uverbs_dev->dev->ops = device->mmap ? &uverbs_mmap_fops : &uverbs_fops;
+	kobject_set_name(&uverbs_dev->dev->kobj, "uverbs%d", uverbs_dev->devnum);
+	if (cdev_add(uverbs_dev->dev, IB_UVERBS_BASE_DEV + uverbs_dev->devnum, 1))
+		goto err_cdev;
+
+	uverbs_dev->class_dev = class_device_create(uverbs_class, NULL,
+						    uverbs_dev->dev->dev,
+						    device->dma_device,
+						    "uverbs%d", uverbs_dev->devnum);
+	if (IS_ERR(uverbs_dev->class_dev))
+		goto err_cdev;
+
+	class_set_devdata(uverbs_dev->class_dev, uverbs_dev);
+
+	if (class_device_create_file(uverbs_dev->class_dev, &class_device_attr_ibdev))
+		goto err_class;
+	if (class_device_create_file(uverbs_dev->class_dev, &class_device_attr_abi_version))
+		goto err_class;
+	if (class_device_create_file(uverbs_dev->class_dev, &class_device_attr_ref_cnt))
+		goto err_class;
+
+	spin_lock(&map_lock);
+	dev_table[uverbs_dev->devnum] = uverbs_dev;
+	spin_unlock(&map_lock);
+
+	ib_set_client_data(device, &uverbs_client, uverbs_dev);
+
+	return;
+
+err_class:
+	class_device_destroy(uverbs_class, uverbs_dev->dev->dev);
+
+err_cdev:
+	cdev_del(uverbs_dev->dev);
+	clear_bit(uverbs_dev->devnum, dev_map);
+
+err:
+	kref_put(&uverbs_dev->ref, ib_uverbs_release_dev);
+	wait_for_completion(&uverbs_dev->comp);
+	kfree(uverbs_dev);
+	return;
+}
+
+static void ib_uverbs_remove_one(struct ib_device *device)
+{
+	struct ib_uverbs_device *uverbs_dev = ib_get_client_data(device, &uverbs_client);
+
+	if (!uverbs_dev)
+		return;
+
+	class_set_devdata(uverbs_dev->class_dev, NULL);
+	class_device_destroy(uverbs_class, uverbs_dev->dev->dev);
+	cdev_del(uverbs_dev->dev);
+
+	spin_lock(&map_lock);
+	dev_table[uverbs_dev->devnum] = NULL;
+	spin_unlock(&map_lock);
+
+	clear_bit(uverbs_dev->devnum, dev_map);
+
+	kref_put(&uverbs_dev->ref, ib_uverbs_release_dev);
+	wait_for_completion(&uverbs_dev->comp);
+	kfree(uverbs_dev);
+}
+
+static struct super_block *uverbs_event_get_sb(struct file_system_type *fs_type, int flags,
+			       const char *dev_name, void *data)
+{
+	return get_sb_pseudo(fs_type, "infinibandevent:", NULL,
+			     INFINIBANDEVENTFS_MAGIC);
+}
 
+static struct file_system_type uverbs_event_fs = {
+	/* No owner field so module can be unloaded */
+	.name    = "infinibandeventfs",
+	.get_sb  = uverbs_event_get_sb,
+	.kill_sb = kill_litter_super
+};
+
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
 static char *uverbs_devnode(struct device *dev, umode_t *mode)
 #else
@@ -1342,6 +1563,7 @@ static char *uverbs_devnode(struct device *dev, mode_t *mode)
 		*mode = 0666;
 	return kasprintf(GFP_KERNEL, "infiniband/%s", dev_name(dev));
 }
+#endif /* LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16) */
 
 static int __init ib_uverbs_init(void)
 {
@@ -1361,7 +1583,9 @@ static int __init ib_uverbs_init(void)
 		goto out_chrdev;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	uverbs_class->devnode = uverbs_devnode;
+#endif
 
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,34))
 	ret = class_create_file(uverbs_class, &class_attr_abi_version.attr);
@@ -1373,14 +1597,49 @@ static int __init ib_uverbs_init(void)
 		goto out_class;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	ret = ib_register_client(&uverbs_client);
 	if (ret) {
 		printk(KERN_ERR "user_verbs: couldn't register client\n");
 		goto out_class;
 	}
+#else
+	ret = class_create_file(uverbs_class, &class_attr_ref_cnt);
+	if (ret) {
+		printk(KERN_ERR "user_verbs: couldn't create ref_cnt attribute\n");
+		goto out_class;
+	}
+
+	ret = register_filesystem(&uverbs_event_fs);
+	if (ret) {
+		printk(KERN_ERR "user_verbs: couldn't register infinibandeventfs\n");
+		goto out_class;
+	}
+
+	uverbs_event_mnt = kern_mount(&uverbs_event_fs);
+	if (IS_ERR(uverbs_event_mnt)) {
+		ret = PTR_ERR(uverbs_event_mnt);
+		printk(KERN_ERR "user_verbs: couldn't mount infinibandeventfs\n");
+		goto out_fs;
+	}
+
+
+	ret = ib_register_client(&uverbs_client);
+	if (ret) {
+		printk(KERN_ERR "user_verbs: couldn't register client\n");
+		goto out_mnt;
+	}
+#endif
 
 	return 0;
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,16))
+out_mnt:
+	mntput(uverbs_event_mnt);
+
+out_fs:
+	unregister_filesystem(&uverbs_event_fs);
+#endif
 out_class:
 	class_destroy(uverbs_class);
 
@@ -1394,10 +1653,16 @@ out:
 static void __exit ib_uverbs_cleanup(void)
 {
 	ib_unregister_client(&uverbs_client);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,16))
+	mntput(uverbs_event_mnt);
+	unregister_filesystem(&uverbs_event_fs);
+#endif
 	class_destroy(uverbs_class);
 	unregister_chrdev_region(IB_UVERBS_BASE_DEV, IB_UVERBS_MAX_DEVICES);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 	if (overflow_maj)
 		unregister_chrdev_region(overflow_maj, IB_UVERBS_MAX_DEVICES);
+#endif
 	idr_destroy(&ib_uverbs_pd_idr);
 	idr_destroy(&ib_uverbs_mr_idr);
 	idr_destroy(&ib_uverbs_mw_idr);
diff --git a/drivers/infiniband/core/verbs.c b/drivers/infiniband/core/verbs.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/verbs.c
+++ b/drivers/infiniband/core/verbs.c
@@ -194,10 +194,13 @@ int ib_init_ah_from_wc(struct ib_device *device, u8 port_num, struct ib_wc *wc,
 	u32 flow_class;
 	u16 gid_index;
 	int ret;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	int is_eth = (rdma_port_get_link_layer(device, port_num) ==
 			IB_LINK_LAYER_ETHERNET);
+#endif
 
 	memset(ah_attr, 0, sizeof *ah_attr);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	if (is_eth) {
 		if (!(wc->wc_flags & IB_WC_GRH))
 			return -EPROTOTYPE;
@@ -215,6 +218,7 @@ int ib_init_ah_from_wc(struct ib_device *device, u8 port_num, struct ib_wc *wc,
 	} else {
 		ah_attr->vlan_id = 0xffff;
 	}
+#endif
 
 
 	ah_attr->dlid = wc->slid;
diff --git a/include/rdma/ib_addr.h b/include/rdma/ib_addr.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_addr.h
+++ b/include/rdma/ib_addr.h
@@ -46,6 +46,9 @@
 #include <net/ip.h>
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_pack.h>
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+#include <linux/ethtool.h>
+#endif
 
 struct rdma_addr_client {
 	atomic_t refcount;
@@ -184,7 +187,11 @@ static inline void iboe_addr_get_sgid(struct rdma_dev_addr *dev_addr,
 	struct net_device *dev;
 	struct in_device *ip4;
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	dev = dev_get_by_index(&init_net, dev_addr->bound_dev_if);
+#else
+	dev = dev_get_by_index(dev_addr->bound_dev_if);
+#endif
 	if (dev) {
 		ip4 = (struct in_device *)dev->ip_ptr;
 		if (ip4 && ip4->ifa_list && ip4->ifa_list->ifa_address)
@@ -244,6 +251,7 @@ static inline enum ib_mtu iboe_get_mtu(int mtu)
 static inline int iboe_get_rate(struct net_device *dev)
 {
 	struct ethtool_cmd cmd;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	u32 speed;
 	int err;
 
@@ -264,6 +272,22 @@ static inline int iboe_get_rate(struct net_device *dev)
 		return IB_RATE_10_GBPS;
 	else
 		return IB_RATE_PORT_CURRENT;
+#else
+	if (!dev->ethtool_ops || !dev->ethtool_ops->get_settings ||
+	    dev->ethtool_ops->get_settings(dev, &cmd))
+		return IB_RATE_PORT_CURRENT;
+
+	if (cmd.speed >= 40000)
+		return IB_RATE_40_GBPS;
+	else if (cmd.speed >= 30000)
+		return IB_RATE_30_GBPS;
+	else if (cmd.speed >= 20000)
+		return IB_RATE_20_GBPS;
+	else if (cmd.speed >= 10000)
+		return IB_RATE_10_GBPS;
+	else
+		return IB_RATE_PORT_CURRENT;
+#endif
 }
 
 static inline int rdma_link_local_addr(struct in6_addr *addr)
diff --git a/include/rdma/ib_cm.h b/include/rdma/ib_cm.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_cm.h
+++ b/include/rdma/ib_cm.h
@@ -262,6 +262,7 @@ struct ib_cm_event {
 	void			*private_data;
 };
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #define CM_REQ_ATTR_ID		cpu_to_be16(0x0010)
 #define CM_MRA_ATTR_ID		cpu_to_be16(0x0011)
 #define CM_REJ_ATTR_ID		cpu_to_be16(0x0012)
@@ -273,6 +274,19 @@ struct ib_cm_event {
 #define CM_SIDR_REP_ATTR_ID	cpu_to_be16(0x0018)
 #define CM_LAP_ATTR_ID		cpu_to_be16(0x0019)
 #define CM_APR_ATTR_ID		cpu_to_be16(0x001A)
+#else
+#define CM_REQ_ATTR_ID		__constant_htons(0x0010)
+#define CM_MRA_ATTR_ID		__constant_htons(0x0011)
+#define CM_REJ_ATTR_ID		__constant_htons(0x0012)
+#define CM_REP_ATTR_ID		__constant_htons(0x0013)
+#define CM_RTU_ATTR_ID		__constant_htons(0x0014)
+#define CM_DREQ_ATTR_ID		__constant_htons(0x0015)
+#define CM_DREP_ATTR_ID		__constant_htons(0x0016)
+#define CM_SIDR_REQ_ATTR_ID	__constant_htons(0x0017)
+#define CM_SIDR_REP_ATTR_ID	__constant_htons(0x0018)
+#define CM_LAP_ATTR_ID		__constant_htons(0x0019)
+#define CM_APR_ATTR_ID		__constant_htons(0x001A)
+#endif
 
 /**
  * ib_cm_handler - User-defined callback to process communication events.
diff --git a/include/rdma/ib_pma.h b/include/rdma/ib_pma.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_pma.h
+++ b/include/rdma/ib_pma.h
@@ -40,6 +40,7 @@
 /*
  * PMA class portinfo capability mask bits
  */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #define IB_PMA_CLASS_CAP_ALLPORTSELECT  cpu_to_be16(1 << 8)
 #define IB_PMA_CLASS_CAP_EXT_WIDTH      cpu_to_be16(1 << 9)
 #define IB_PMA_CLASS_CAP_XMIT_WAIT      cpu_to_be16(1 << 12)
@@ -50,6 +51,17 @@
 #define IB_PMA_PORT_COUNTERS            cpu_to_be16(0x0012)
 #define IB_PMA_PORT_COUNTERS_EXT        cpu_to_be16(0x001D)
 #define IB_PMA_PORT_SAMPLES_RESULT_EXT  cpu_to_be16(0x001E)
+#else
+#define IB_PMA_CLASS_CAP_ALLPORTSELECT  0x0001
+#define IB_PMA_CLASS_CAP_EXT_WIDTH      0x0002
+#define IB_PMA_CLASS_CAP_XMIT_WAIT      0x0010
+#define IB_PMA_CLASS_PORT_INFO          0x0100
+#define IB_PMA_PORT_SAMPLES_CONTROL     0x1000
+#define IB_PMA_PORT_SAMPLES_RESULT      0x1100
+#define IB_PMA_PORT_COUNTERS            0x1200
+#define IB_PMA_PORT_COUNTERS_EXT        0x1d00
+#define IB_PMA_PORT_SAMPLES_RESULT_EXT  0x1e00
+#endif
 
 struct ib_pma_mad {
 	struct ib_mad_hdr mad_hdr;
diff --git a/include/rdma/ib_smi.h b/include/rdma/ib_smi.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_smi.h
+++ b/include/rdma/ib_smi.h
@@ -38,6 +38,7 @@
 #define IB_SMI_H
 
 #include <rdma/ib_mad.h>
+#include <asm/byteorder.h>
 
 #define IB_SMP_DATA_SIZE			64
 #define IB_SMP_MAX_PATH_HOPS			64
@@ -66,6 +67,7 @@ struct ib_smp {
 #define IB_SMP_DIRECTION			cpu_to_be16(0x8000)
 
 /* Subnet management attributes */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #define IB_SMP_ATTR_NOTICE			cpu_to_be16(0x0002)
 #define IB_SMP_ATTR_NODE_DESC			cpu_to_be16(0x0010)
 #define IB_SMP_ATTR_NODE_INFO			cpu_to_be16(0x0011)
@@ -82,6 +84,24 @@ struct ib_smp {
 #define IB_SMP_ATTR_VENDOR_DIAG			cpu_to_be16(0x0030)
 #define IB_SMP_ATTR_LED_INFO			cpu_to_be16(0x0031)
 #define IB_SMP_ATTR_VENDOR_MASK			cpu_to_be16(0xFF00)
+#else
+#define IB_SMP_ATTR_NOTICE			0x0200
+#define IB_SMP_ATTR_NODE_DESC			0x1000
+#define IB_SMP_ATTR_NODE_INFO			0x1100
+#define IB_SMP_ATTR_SWITCH_INFO			0x1200
+#define IB_SMP_ATTR_GUID_INFO			0x1400
+#define IB_SMP_ATTR_PORT_INFO			0x1500
+#define IB_SMP_ATTR_PKEY_TABLE			0x1600
+#define IB_SMP_ATTR_SL_TO_VL_TABLE		0x1700
+#define IB_SMP_ATTR_VL_ARB_TABLE		0x1800
+#define IB_SMP_ATTR_LINEAR_FORWARD_TABLE	0x1900
+#define IB_SMP_ATTR_RANDOM_FORWARD_TABLE	0x1a00
+#define IB_SMP_ATTR_MCAST_FORWARD_TABLE		0x1b00
+#define IB_SMP_ATTR_SM_INFO			0x2000
+#define IB_SMP_ATTR_VENDOR_DIAG			0x3000
+#define IB_SMP_ATTR_LED_INFO			0x3100
+#define IB_SMP_ATTR_VENDOR_MASK			0x00ff
+#endif
 
 struct ib_port_info {
 	__be64 mkey;
diff --git a/include/rdma/ib_umem.h b/include/rdma/ib_umem.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_umem.h
+++ b/include/rdma/ib_umem.h
@@ -37,7 +37,9 @@
 #include <linux/scatterlist.h>
 #include <linux/workqueue.h>
 #include <linux/dma-attrs.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 #include <rdma/ib_peer_mem.h>
+#endif
 
 struct ib_ucontext;
 struct ib_umem;
diff --git a/include/rdma/ib_user_verbs.h b/include/rdma/ib_user_verbs.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_user_verbs.h
+++ b/include/rdma/ib_user_verbs.h
@@ -45,6 +45,10 @@
 #define IB_USER_VERBS_ABI_VERSION	6
 #define IB_USER_VERBS_CMD_THRESHOLD    50
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+#define IB_USER_VERBS_REF_CNT		1
+#endif
+
 /*
  * To support 6 legacy commands using the old extension style
  */
diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@ -1818,6 +1818,9 @@ struct ib_device {
 
 	struct module               *owner;
 	struct device                dev;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+	struct class_device          class_dev;
+#endif
 	struct kobject               *ports_parent;
 	struct list_head             port_list;
 
@@ -2328,7 +2331,11 @@ static inline int ib_dma_mapping_error(struct ib_device *dev, u64 dma_addr)
 {
 	if (dev->dma_ops)
 		return dev->dma_ops->mapping_error(dev, dma_addr);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 16))
 	return dma_mapping_error(dev->dma_device, dma_addr);
+#else
+	return dma_mapping_error(dma_addr);
+#endif
 }
 
 /**
diff --git a/include/rdma/peer_mem.h b/include/rdma/peer_mem.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/rdma/peer_mem.h
+++ b/include/rdma/peer_mem.h
@@ -38,6 +38,9 @@
 #include <linux/slab.h>
 #include <linux/errno.h>
 #include <linux/export.h>
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 16))
+#include <linux/scatterlist.h>
+#endif
 
 
 #define IB_PEER_MEMORY_NAME_MAX 64
