From: Vladimir Sokolovsky <vlad@mellanox.com>
Subject: [PATCH] BACKPORT: Added support for kernel 3.9

issue: none

Change-Id: Ie414a25f3a13f0ad7b4797f78d45903b778db9aa
Signed-off-by: Vladimir Sokolovsky <vlad@mellanox.com>
---
 drivers/infiniband/core/cm.c                   |    4 +
 drivers/infiniband/core/cma.c                  |    6 ++
 drivers/infiniband/core/fmr_pool.c             |    6 ++
 drivers/infiniband/hw/mlx4/cm.c                |    4 +
 drivers/infiniband/hw/mlx4/main.c              |    4 +
 drivers/net/eipoib/eth_ipoib_main.c            |   84 ++++++++++++++++++++++++
 drivers/net/eipoib/eth_ipoib_multicast.c       |    4 +
 drivers/net/eipoib/eth_ipoib_sysfs.c           |    4 +
 drivers/net/ethernet/mellanox/mlx4/en_netdev.c |   38 +++++++++++
 drivers/net/ethernet/mellanox/mlx4/en_rx.c     |    6 ++
 net/rds/bind.c                                 |    7 ++-
 net/rds/connection.c                           |   16 +++++
 net/sunrpc/xprtrdma/rpc_rdma.c                 |    8 ++
 net/sunrpc/xprtrdma/transport.c                |   25 +++++++
 net/sunrpc/xprtrdma/xprt_rdma.h                |   15 ++++
 15 files changed, 230 insertions(+), 1 deletions(-)

diff --git a/drivers/infiniband/core/cm.c b/drivers/infiniband/core/cm.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@ -417,7 +417,11 @@ static int cm_alloc_id(struct cm_id_private *cm_id_priv)
 		ret = idr_get_new_above(&cm.local_id_table, cm_id_priv,
 					next_id, &id);
 		if (!ret)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			next_id = ((unsigned) id + 1) & MAX_IDR_MASK;
+#else
+			next_id = max(id + 1, 0);
+#endif
 		spin_unlock_irqrestore(&cm.lock, flags);
 	} while( (ret == -EAGAIN) && idr_pre_get(&cm.local_id_table, GFP_KERNEL) );
 
diff --git a/drivers/infiniband/core/cma.c b/drivers/infiniband/core/cma.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -2379,10 +2379,16 @@ static int cma_check_port(struct rdma_bind_list *bind_list,
 {
 	struct rdma_id_private *cur_id;
 	struct sockaddr *addr, *cur_addr;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *node;
+#endif
 
 	addr = (struct sockaddr *) &id_priv->id.route.addr.src_addr;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry(cur_id, node, &bind_list->owners, node) {
+#else
+	hlist_for_each_entry(cur_id, &bind_list->owners, node) {
+#endif
 		if (id_priv == cur_id)
 			continue;
 
diff --git a/drivers/infiniband/core/fmr_pool.c b/drivers/infiniband/core/fmr_pool.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/core/fmr_pool.c
+++ b/drivers/infiniband/core/fmr_pool.c
@@ -118,14 +118,20 @@ static inline struct ib_pool_fmr *ib_fmr_cache_lookup(struct ib_fmr_pool *pool,
 {
 	struct hlist_head *bucket;
 	struct ib_pool_fmr *fmr;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *pos;
+#endif
 
 	if (!pool->cache_bucket)
 		return NULL;
 
 	bucket = pool->cache_bucket + ib_fmr_hash(*page_list);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry(fmr, pos, bucket, cache_node)
+#else
+	hlist_for_each_entry(fmr, bucket, cache_node)
+#endif
 		if (io_virtual_address == fmr->io_virtual_address &&
 		    page_list_len      == fmr->page_list_len      &&
 		    !memcmp(page_list, fmr->page_list,
diff --git a/drivers/infiniband/hw/mlx4/cm.c b/drivers/infiniband/hw/mlx4/cm.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/hw/mlx4/cm.c
+++ b/drivers/infiniband/hw/mlx4/cm.c
@@ -264,7 +264,11 @@ id_map_alloc(struct ib_device *ibdev, int slave_id, u32 sl_cm_id)
 		ret = idr_get_new_above(&sriov->pv_id_table, ent,
 					next_id, &id);
 		if (!ret) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			next_id = ((unsigned) id + 1) & MAX_IDR_MASK;
+#else
+			next_id = max(ret + 1, 0);
+#endif
 			ent->pv_cm_id = (u32)id;
 			sl_id_map_add(ibdev, ent);
 		}
diff --git a/drivers/infiniband/hw/mlx4/main.c b/drivers/infiniband/hw/mlx4/main.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/hw/mlx4/main.c
+++ b/drivers/infiniband/hw/mlx4/main.c
@@ -1964,7 +1964,11 @@ static void mlx4_ib_scan_netdevs(struct mlx4_ib_dev *ibdev,
 		    event == NETDEV_CHANGEADDR)
 			init = 1;
 		if (iboe->netdevs[port - 1] && netif_is_bond_slave(iboe->netdevs[port - 1]))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			iboe->masters[port - 1] = iboe->netdevs[port - 1]->master;
+#else
+			iboe->masters[port - 1] = netdev_master_upper_dev_get(iboe->netdevs[port - 1]);
+#endif
 
 		/* if bonding is used it is possible that we add it to masters only after
 		   IP address is assigned to the net bonding interface */
diff --git a/drivers/net/eipoib/eth_ipoib_main.c b/drivers/net/eipoib/eth_ipoib_main.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/eipoib/eth_ipoib_main.c
+++ b/drivers/net/eipoib/eth_ipoib_main.c
@@ -248,7 +248,11 @@ static inline int netdev_set_parent_master(struct net_device *slave,
 
 	ASSERT_RTNL();
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	err = netdev_set_master(slave, master);
+#else
+	err = netdev_master_upper_dev_link(slave, master);
+#endif
 	if (err)
 		return err;
 	if (master) {
@@ -303,7 +307,11 @@ static inline int is_parent_mac(struct net_device *dev, u8 *mac)
 
 static inline int __is_slave(struct net_device *dev)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	return dev->master && is_parent(dev->master);
+#else
+	return netdev_master_upper_dev_get(dev) && is_parent(netdev_master_upper_dev_get(dev));
+#endif
 }
 
 static inline int is_slave(struct net_device *dev)
@@ -721,7 +729,11 @@ int parent_release_slave(struct net_device *parent_dev,
 
 	/* slave is not a slave or master is not master of this slave */
 	if (!(slave_dev->flags & IFF_SLAVE) ||
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	    (slave_dev->master != parent_dev)) {
+#else
+	    (netdev_master_upper_dev_get(slave_dev) != parent_dev)) {
+#endif
 		pr_err("%s cannot release %s.\n",
 		       parent_dev->name, slave_dev->name);
 		return -EINVAL;
@@ -919,10 +931,16 @@ static inline int eipoib_mac_hash(const unsigned char *mac)
 static struct neigh *neigh_find(struct hlist_head *head,
 				const u8 *addr)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *h;
+#endif
 	struct neigh *neigh;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry(neigh, h, head, hlist) {
+#else
+	hlist_for_each_entry(neigh, head, hlist) {
+#endif
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,5,0))
 		if (ether_addr_equal(neigh->emac, addr))
 #else
@@ -936,10 +954,16 @@ static struct neigh *neigh_find(struct hlist_head *head,
 static struct neigh *neigh_find_rcu(struct hlist_head *head,
 				const u8 *addr)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *h;
+#endif
 	struct neigh *neigh;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry_rcu(neigh, h, head, hlist) {
+#else
+	hlist_for_each_entry_rcu(neigh, head, hlist) {
+#endif
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,5,0))
 		if (ether_addr_equal(neigh->emac, addr))
 #else
@@ -1073,8 +1097,13 @@ static void slave_neigh_flush(struct slave *slave)
 	spin_lock_bh(&slave->hash_lock);
 	for (i = 0; i < NEIGH_HASH_SIZE; i++) {
 		struct neigh *neigh;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		struct hlist_node *h, *n;
 		hlist_for_each_entry_safe(neigh, h, n, &slave->hash[i], hlist) {
+#else
+		struct hlist_node *n;
+		hlist_for_each_entry_safe(neigh, n, &slave->hash[i], hlist) {
+#endif
 			/* perhasps use neigh_delete instead of eipoib_neigh_put? */
 			eipoib_neigh_put(neigh);
 		}
@@ -1104,8 +1133,13 @@ static void slave_neigh_reap(struct parent *parent, struct slave *slave)
 
 	for (i = 0; i < NEIGH_HASH_SIZE; i++) {
 		struct neigh *neigh;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		struct hlist_node *h, *n;
 		hlist_for_each_entry_safe(neigh, h, n, &slave->hash[i], hlist) {
+#else
+		struct hlist_node *n;
+		hlist_for_each_entry_safe(neigh, n, &slave->hash[i], hlist) {
+#endif
 			int is_mc_neigh = 0;
 			/* check if the time is bigger than allowed */
 			/* was the neigh idle for two GC periods */
@@ -1162,7 +1196,11 @@ struct neigh *eipoib_neigh_get(struct slave *slave, const u8 *emac)
 static int neigh_learn(struct slave *slave, struct sk_buff *skb, u8 *remac)
 {
 	struct net_device *dev = slave->dev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *parent_dev = dev->master;
+#else
+	struct net_device *parent_dev = netdev_master_upper_dev_get(dev);
+#endif
 	struct parent *parent = netdev_priv(parent_dev);
 	int rc;
 	struct learn_neigh_info *learn_neigh;
@@ -1540,6 +1578,9 @@ static struct sk_buff *get_slave_skb_arp(struct slave *slave,
 	struct eth_arp_data *arp_data = (struct eth_arp_data *)
 					(skb->data + sizeof(struct ethhdr) +
 					 sizeof(struct arphdr));
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,9,0))
+	struct net_device *upper_dev = netdev_master_upper_dev_get(slave->dev);
+#endif
 	u8 t_addr[ETH_ALEN] = {0};
 	int err = 0;
 	/* mark regular packet handling */
@@ -1552,7 +1593,11 @@ static struct sk_buff *get_slave_skb_arp(struct slave *slave,
 	 * arp request for all these IP's.
 	 */
 	if (skb->protocol == htons(ETH_P_ARP))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		err = add_emac_ip_info(slave->dev->master, arp_data->arp_sip,
+#else
+		err = add_emac_ip_info(upper_dev, arp_data->arp_sip,
+#endif
 				       arp_data->arp_sha, slave->vlan, GFP_ATOMIC);
 	if (err && err != -EINVAL)
 		pr_warn("%s: Failed creating: emac_ip_info for ip: %pI4 err: %d",
@@ -1566,14 +1611,22 @@ static struct sk_buff *get_slave_skb_arp(struct slave *slave,
 	 */
 	arp_data->arp_dha[0] = arp_data->arp_dha[0] & 0xFD;
 	if (htons(ARPOP_REPLY) == (arphdr->ar_op) &&
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	    !memcmp(arp_data->arp_dha, slave->dev->master->dev_addr, ETH_ALEN)) {
+#else
+	    !memcmp(arp_data->arp_dha, upper_dev->dev_addr, ETH_ALEN)) {
+#endif
 		/*
 		 * when the source is the parent interface, assumes
 		 * that we are in the middle of live migration process,
 		 * so, we will send gratuitous arp.
 		 */
 		pr_info("%s: Arp packet for parent: %s",
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			__func__, slave->dev->master->name);
+#else
+			__func__, upper_dev->name);
+#endif
 		/* create gratuitous ARP on behalf of the guest */
 		nskb = arp_create(ARPOP_REQUEST,
 				  be16_to_cpu(skb->protocol),
@@ -1631,7 +1684,11 @@ static void get_slave_skb_arp_by_ip(struct slave *slave,
 		       __func__, slave->dev->name);
 
 	/* add new source IP as served via the driver. */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	ret = add_emac_ip_info(slave->dev->master, iph->saddr, ethh->h_source,
+#else
+	ret = add_emac_ip_info(netdev_master_upper_dev_get(slave->dev), iph->saddr, ethh->h_source,
+#endif
 			     slave->vlan, GFP_ATOMIC);
 	if (ret && ret != -EINVAL)
 		pr_warn("%s: Failed creating: emac_ip_info for ip: %pI4 mac: %pM",
@@ -1739,7 +1796,11 @@ out:
 static struct sk_buff *get_slave_skb(struct slave *slave, struct sk_buff *skb)
 {
 	struct net_device *dev = slave->dev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *parent_dev = dev->master;
+#else
+	struct net_device *parent_dev = netdev_master_upper_dev_get(dev);
+#endif
 	struct parent *parent = netdev_priv(parent_dev);
 	struct sk_buff *nskb = NULL;
 	struct ethhdr *ethh = (struct ethhdr *)(skb->data);
@@ -1852,7 +1913,11 @@ static struct sk_buff *get_parent_skb_arp(struct slave *slave,
 					  struct sk_buff *skb,
 					  u8 *remac)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *dev = slave->dev->master;
+#else
+	struct net_device *dev = netdev_master_upper_dev_get(slave->dev);
+#endif
 	struct sk_buff *nskb;
 	struct arphdr *arphdr = (struct arphdr *)(skb->data);
 	struct ipoib_arp_data *arp_data = (struct ipoib_arp_data *)
@@ -1864,10 +1929,17 @@ static struct sk_buff *get_parent_skb_arp(struct slave *slave,
 	/* live migration: gets arp with broadcast src and dst */
 	if (!memcmp(arp_data->arp_sha, slave->dev->broadcast, INFINIBAND_ALEN) &&
 	    !memcmp(arp_data->arp_dha, slave->dev->broadcast, INFINIBAND_ALEN)) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		pr_info("%s: ARP with bcast src and dest send from src_hw: %pM\n",
 			__func__, slave->dev->master->dev_addr);
 		/* replace the src with the parent src: */
 		memcpy(local_eth_addr, slave->dev->master->dev_addr, ETH_ALEN);
+#else
+		pr_info("%s: ARP with bcast src and dest send from src_hw: %pM\n",
+			__func__, dev->dev_addr);
+		/* replace the src with the parent src: */
+		memcpy(local_eth_addr, dev->dev_addr, ETH_ALEN);
+#endif
 		/*
 		 * set local administrated bit,
 		 * that way the bridge will not throws it
@@ -1905,7 +1977,11 @@ static struct sk_buff *get_parent_skb_ip(struct slave *slave,
 static struct sk_buff *get_parent_skb(struct slave *slave,
 				      struct sk_buff *skb, u8 *remac)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *dev = slave->dev->master;
+#else
+	struct net_device *dev = netdev_master_upper_dev_get(slave->dev);
+#endif
 	struct sk_buff *nskb = NULL;
 	struct ethhdr *ethh;
 
@@ -2010,7 +2086,11 @@ int add_vlan_and_send(struct parent *parent, int vlan_tag,
 static int parent_rx(struct sk_buff *skb, struct slave *slave)
 {
 	struct net_device *slave_dev = skb->dev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *parent_dev = slave_dev->master;
+#else
+	struct net_device *parent_dev = netdev_master_upper_dev_get(slave_dev);
+#endif
 	struct parent *parent = netdev_priv(parent_dev);
 	struct eipoib_cb_data *data = IPOIB_HANDLER_CB(skb);
 	struct napi_struct *napi =  data->rx.napi;
@@ -2552,7 +2632,11 @@ static int parent_master_netdev_event(unsigned long event,
 static int parent_slave_netdev_event(unsigned long event,
 				     struct net_device *slave_dev)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *parent_dev = slave_dev->master;
+#else
+	struct net_device *parent_dev = netdev_master_upper_dev_get(slave_dev);
+#endif
 	struct parent *parent = netdev_priv(parent_dev);
 
 	if (!parent_dev) {
diff --git a/drivers/net/eipoib/eth_ipoib_multicast.c b/drivers/net/eipoib/eth_ipoib_multicast.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/eipoib/eth_ipoib_multicast.c
+++ b/drivers/net/eipoib/eth_ipoib_multicast.c
@@ -147,7 +147,11 @@ struct sk_buff *gen_igmp_v2_query(struct slave *slave)
 	struct ethhdr  *ethhdr;
 	struct iphdr   *iph;
 	struct igmphdr *igmph;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct net_device *dev = slave->dev->master;
+#else
+	struct net_device *dev = netdev_master_upper_dev_get(slave->dev);
+#endif
 	u8 *p_options;
 	int size;
 
diff --git a/drivers/net/eipoib/eth_ipoib_sysfs.c b/drivers/net/eipoib/eth_ipoib_sysfs.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/eipoib/eth_ipoib_sysfs.c
+++ b/drivers/net/eipoib/eth_ipoib_sysfs.c
@@ -112,8 +112,12 @@ static ssize_t parent_show_neighs(struct device *d,
 	parent_for_each_slave_rcu(parent, slave) {
 		for (i = 0; i < NEIGH_HASH_SIZE; i++) {
 			struct neigh *neigh;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			struct hlist_node *n;
 			hlist_for_each_entry_rcu(neigh, n, &slave->hash[i], hlist)
+#else
+			hlist_for_each_entry_rcu(neigh, &slave->hash[i], hlist)
+#endif
 				p += _sprintf(p, buf, "SLAVE=%-10s EMAC=%pM IMAC=%pM:%pM:%pM:%.2x:%.2x\n",
 					      slave->dev->name,
 					      neigh->emac,
diff --git a/drivers/net/ethernet/mellanox/mlx4/en_netdev.c b/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
@@ -280,11 +280,17 @@ static inline struct mlx4_en_filter *
 mlx4_en_filter_find(struct mlx4_en_priv *priv, __be32 src_ip, __be32 dst_ip,
 		    u8 ip_proto, __be16 src_port, __be16 dst_port)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *elem;
+#endif
 	struct mlx4_en_filter *filter;
 	struct mlx4_en_filter *ret = NULL;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry(filter, elem,
+#else
+	hlist_for_each_entry(filter,
+#endif
 			     filter_hash_bucket(priv, src_ip, dst_ip,
 						src_port, dst_port),
 			     filter_chain) {
@@ -653,13 +659,21 @@ static void mlx4_en_put_qp(struct mlx4_en_priv *priv)
 		mlx4_unregister_mac(dev, priv->port, mac);
 	} else {
 		struct mlx4_mac_entry *entry;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		struct hlist_node *n, *tmp;
+#else
+		struct hlist_node *tmp;
+#endif
 		struct hlist_head *bucket;
 		unsigned int i;
 
 		for (i = 0; i < MLX4_EN_MAC_HASH_SIZE; ++i) {
 			bucket = &priv->mac_hash[i];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			hlist_for_each_entry_safe(entry, n, tmp, bucket, hlist) {
+#else
+			hlist_for_each_entry_safe(entry, tmp, bucket, hlist) {
+#endif
 				mac = mlx4_mac_to_u64(entry->mac);
 				en_dbg(DRV, priv, "Registering MAC: %pM for deleting\n",
 				       entry->mac);
@@ -691,11 +705,19 @@ static int mlx4_en_replace_mac(struct mlx4_en_priv *priv, int qpn,
 		struct hlist_head *bucket;
 		unsigned int mac_hash;
 		struct mlx4_mac_entry *entry;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		struct hlist_node *n, *tmp;
+#else
+		struct hlist_node *tmp;
+#endif
 		u64 prev_mac_u64 = mlx4_mac_to_u64(prev_mac);
 
 		bucket = &priv->mac_hash[prev_mac[MLX4_EN_MAC_HASH_IDX]];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		hlist_for_each_entry_safe(entry, n, tmp, bucket, hlist) {
+#else
+		hlist_for_each_entry_safe(entry, tmp, bucket, hlist) {
+#endif
 			if (ether_addr_equal_64bits(entry->mac, prev_mac)) {
 				mlx4_en_uc_steer_release(priv, entry->mac,
 							 qpn, entry->reg_id);
@@ -1100,7 +1122,11 @@ static void mlx4_en_do_uc_filter(struct mlx4_en_priv *priv,
 {
 	struct netdev_hw_addr *ha;
 	struct mlx4_mac_entry *entry;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *n, *tmp;
+#else
+	struct hlist_node *tmp;
+#endif
 	bool found;
 	u64 mac;
 	int err = 0;
@@ -1116,7 +1142,11 @@ static void mlx4_en_do_uc_filter(struct mlx4_en_priv *priv,
 	/* find what to remove */
 	for (i = 0; i < MLX4_EN_MAC_HASH_SIZE; ++i) {
 		bucket = &priv->mac_hash[i];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		hlist_for_each_entry_safe(entry, n, tmp, bucket, hlist) {
+#else
+		hlist_for_each_entry_safe(entry, tmp, bucket, hlist) {
+#endif
 			found = false;
 			netdev_for_each_uc_addr(ha, dev) {
 				if (ether_addr_equal_64bits(entry->mac,
@@ -1160,7 +1190,11 @@ static void mlx4_en_do_uc_filter(struct mlx4_en_priv *priv,
 	netdev_for_each_uc_addr(ha, dev) {
 		found = false;
 		bucket = &priv->mac_hash[ha->addr[MLX4_EN_MAC_HASH_IDX]];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		hlist_for_each_entry(entry, n, bucket, hlist) {
+#else
+		hlist_for_each_entry(entry, bucket, hlist) {
+#endif
 			if (ether_addr_equal_64bits(entry->mac, ha->addr)) {
 				found = true;
 				break;
@@ -2545,7 +2579,11 @@ static int mlx4_en_fdb_add(struct ndmsg *ndm, struct nlattr *tb[],
 	return err;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 static int mlx4_en_fdb_del(struct ndmsg *ndm,
+#else
+static int mlx4_en_fdb_del(struct ndmsg *ndm, struct nlattr *tb[],
+#endif
 			   struct net_device *dev,
 			   const unsigned char *addr)
 {
diff --git a/drivers/net/ethernet/mellanox/mlx4/en_rx.c b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@ -652,7 +652,9 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 		if (priv->flags & MLX4_EN_FLAG_RX_FILTER_NEEDED &&
 		    is_multicast_ether_addr(ethh->h_dest)) {
 			struct mlx4_mac_entry *entry;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			struct hlist_node *n;
+#endif
 			struct hlist_head *bucket;
 			unsigned int mac_hash;
 
@@ -660,7 +662,11 @@ int mlx4_en_process_rx_cq(struct net_device *dev,
 			mac_hash = ethh->h_source[MLX4_EN_MAC_HASH_IDX];
 			bucket = &priv->mac_hash[mac_hash];
 			rcu_read_lock();
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 			hlist_for_each_entry_rcu(entry, n, bucket, hlist) {
+#else
+			hlist_for_each_entry_rcu(entry, bucket, hlist) {
+#endif
 				if (ether_addr_equal_64bits(entry->mac,
 							    ethh->h_source)) {
 					rcu_read_unlock();
diff --git a/net/rds/bind.c b/net/rds/bind.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/net/rds/bind.c
+++ b/net/rds/bind.c
@@ -54,12 +54,17 @@ static struct rds_sock *rds_bind_lookup(__be32 addr, __be16 port,
 					struct rds_sock *insert)
 {
 	struct rds_sock *rs;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *node;
+#endif
 	struct hlist_head *head = hash_to_bucket(addr, port);
 	u64 cmp;
 	u64 needle = ((u64)be32_to_cpu(addr) << 32) | be16_to_cpu(port);
-
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	hlist_for_each_entry(rs, node, head, rs_bound_node) {
+#else
+	hlist_for_each_entry_rcu(rs, head, rs_bound_node) {
+#endif
 		cmp = ((u64)be32_to_cpu(rs->rs_bound_addr) << 32) |
 		      be16_to_cpu(rs->rs_bound_port);
 
diff --git a/net/rds/connection.c b/net/rds/connection.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/net/rds/connection.c
+++ b/net/rds/connection.c
@@ -69,9 +69,13 @@ static struct rds_connection *rds_conn_lookup(struct hlist_head *head,
 					      u8 tos)
 {
 	struct rds_connection *conn, *ret = NULL;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *pos;
 
 	hlist_for_each_entry_rcu(conn, pos, head, c_hash_node) {
+#else
+	hlist_for_each_entry_rcu(conn, head, c_hash_node) {
+#endif
 		if (conn->c_faddr == faddr && conn->c_laddr == laddr &&
 				conn->c_tos == tos &&
 				conn->c_trans == trans) {
@@ -411,7 +415,9 @@ static void rds_conn_message_info(struct socket *sock, unsigned int len,
 				  int want_send)
 {
 	struct hlist_head *head;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *pos;
+#endif
 	struct list_head *list;
 	struct rds_connection *conn;
 	struct rds_message *rm;
@@ -425,7 +431,11 @@ static void rds_conn_message_info(struct socket *sock, unsigned int len,
 
 	for (i = 0, head = rds_conn_hash; i < ARRAY_SIZE(rds_conn_hash);
 	     i++, head++) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		hlist_for_each_entry_rcu(conn, pos, head, c_hash_node) {
+#else
+		hlist_for_each_entry_rcu(conn, head, c_hash_node) {
+#endif
 			if (want_send)
 				list = &conn->c_send_queue;
 			else
@@ -474,7 +484,9 @@ void rds_for_each_conn_info(struct socket *sock, unsigned int len,
 {
 	uint64_t buffer[(item_len + 7) / 8];
 	struct hlist_head *head;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct hlist_node *pos;
+#endif
 	struct rds_connection *conn;
 	size_t i;
 
@@ -485,7 +497,11 @@ void rds_for_each_conn_info(struct socket *sock, unsigned int len,
 
 	for (i = 0, head = rds_conn_hash; i < ARRAY_SIZE(rds_conn_hash);
 	     i++, head++) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 		hlist_for_each_entry_rcu(conn, pos, head, c_hash_node) {
+#else
+		hlist_for_each_entry_rcu(conn, head, c_hash_node) {
+#endif
 
 			/* XXX no c_lock usage.. */
 			if (!visitor(conn, buffer))
diff --git a/net/sunrpc/xprtrdma/rpc_rdma.c b/net/sunrpc/xprtrdma/rpc_rdma.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/net/sunrpc/xprtrdma/rpc_rdma.c
+++ b/net/sunrpc/xprtrdma/rpc_rdma.c
@@ -171,7 +171,11 @@ rpcrdma_create_chunks(struct rpc_rqst *rqst, struct xdr_buf *target,
 		struct rpcrdma_msg *headerp, enum rpcrdma_chunktype type)
 {
 	struct rpcrdma_req *req = rpcr_to_rdmar(rqst);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(rqst->rq_task->tk_xprt);
+#else
+	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(rqst->rq_xprt);
+#endif
 	int nsegs, nchunks = 0;
 	unsigned int pos;
 	struct rpcrdma_mr_seg *seg = req->rl_segments;
@@ -374,7 +378,11 @@ rpcrdma_inline_pullup(struct rpc_rqst *rqst, int pad)
 int
 rpcrdma_marshal_req(struct rpc_rqst *rqst)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct rpc_xprt *xprt = rqst->rq_task->tk_xprt;
+#else
+	struct rpc_xprt *xprt = rqst->rq_xprt;
+#endif
 	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
 	struct rpcrdma_req *req = rpcr_to_rdmar(rqst);
 	char *base;
diff --git a/net/sunrpc/xprtrdma/transport.c b/net/sunrpc/xprtrdma/transport.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/net/sunrpc/xprtrdma/transport.c
+++ b/net/sunrpc/xprtrdma/transport.c
@@ -51,6 +51,9 @@
 #include <linux/init.h>
 #include <linux/slab.h>
 #include <linux/seq_file.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,9,0))
+#include <linux/sunrpc/addr.h>
+#endif
 
 #include "xprt_rdma.h"
 
@@ -85,7 +88,11 @@ static unsigned int max_memreg = RPCRDMA_LAST - 1;
 
 static struct ctl_table_header *sunrpc_table_header;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,11,0))
 static ctl_table xr_tunables_table[] = {
+#else
+static struct ctl_table xr_tunables_table[] = {
+#endif
 	{
 		.procname	= "rdma_slot_table_entries",
 		.data		= &xprt_rdma_slot_table_entries,
@@ -137,7 +144,11 @@ static ctl_table xr_tunables_table[] = {
 	{ },
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,11,0))
 static ctl_table sunrpc_table[] = {
+#else
+static struct ctl_table sunrpc_table[] = {
+#endif
 	{
 		.procname	= "sunrpc",
 		.mode		= 0555,
@@ -431,10 +442,16 @@ xprt_rdma_set_port(struct rpc_xprt *xprt, u16 port)
 	dprintk("RPC:       %s: %u\n", __func__, port);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 static void
 xprt_rdma_connect(struct rpc_task *task)
 {
 	struct rpc_xprt *xprt = (struct rpc_xprt *)task->tk_xprt;
+#else
+static void
+xprt_rdma_connect(struct rpc_xprt *xprt, struct rpc_task *task)
+{
+#endif
 	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
 
 	if (r_xprt->rx_ep.rep_connected != 0) {
@@ -491,7 +508,11 @@ xprt_rdma_reserve_xprt(struct rpc_task *task)
 static void *
 xprt_rdma_allocate(struct rpc_task *task, size_t size)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct rpc_xprt *xprt = task->tk_xprt;
+#else
+	struct rpc_xprt *xprt = task->tk_rqstp->rq_xprt;
+#endif
 	struct rpcrdma_req *req, *nreq;
 
 	req = rpcrdma_buffer_get(&rpcx_to_rdmax(xprt)->rx_buf);
@@ -643,7 +664,11 @@ static int
 xprt_rdma_send_request(struct rpc_task *task)
 {
 	struct rpc_rqst *rqst = task->tk_rqstp;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 	struct rpc_xprt *xprt = task->tk_xprt;
+#else
+	struct rpc_xprt *xprt = rqst->rq_xprt;
+#endif
 	struct rpcrdma_req *req = rpcr_to_rdmar(rqst);
 	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
 
diff --git a/net/sunrpc/xprtrdma/xprt_rdma.h b/net/sunrpc/xprtrdma/xprt_rdma.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/net/sunrpc/xprtrdma/xprt_rdma.h
+++ b/net/sunrpc/xprtrdma/xprt_rdma.h
@@ -234,14 +234,29 @@ struct rpcrdma_create_data_internal {
 	unsigned int	padding;	/* non-rdma write header padding */
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 #define RPCRDMA_INLINE_READ_THRESHOLD(rq) \
 	(rpcx_to_rdmad(rq->rq_task->tk_xprt).inline_rsize)
+#else
+#define RPCRDMA_INLINE_READ_THRESHOLD(rq) \
+	(rpcx_to_rdmad(rq->rq_xprt).inline_rsize)
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 #define RPCRDMA_INLINE_WRITE_THRESHOLD(rq)\
 	(rpcx_to_rdmad(rq->rq_task->tk_xprt).inline_wsize)
+#else
+#define RPCRDMA_INLINE_WRITE_THRESHOLD(rq)\
+	(rpcx_to_rdmad(rq->rq_xprt).inline_wsize)
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
 #define RPCRDMA_INLINE_PAD_VALUE(rq)\
 	rpcx_to_rdmad(rq->rq_task->tk_xprt).padding
+#else
+#define RPCRDMA_INLINE_PAD_VALUE(rq)\
+	rpcx_to_rdmad(rq->rq_xprt).padding
+#endif
 
 /*
  * Statistics for RPCRDMA
